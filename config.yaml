dir:
  results: 'results/'
  dataset: '../data_own/'

shape_dataset:
  id: sub-221CR_ses-20190515T160400 # my
  # id: sub-221CR_ses-20190514T142312
  # id: sub-231CR_ses-20190924T161413 # abhishek
  # id: sub-231CR_ses-20190921T144923
  # id: sub-KM131_ses-20180117T194023
  # id: sub-267CR_ses-20200331T161053
  # id: sub-245CR_ses-20200331T142427
  # id: sub-KF134_ses-20180208T171905

  win_len: 0.1

# mention x for stimulus, choice and rest
dim_x_z: [0, 0, 1, 1, 1]
# dim_x_z: [1, 1, 2]
# dim_x_z: [0, 0, 3]


which_vae: 'vae_gp_combined' # baseline or vae_gp
# which_vae: 'baseline' # baseline or vae_gp

vae_baseline:
  rnn:  
    bidirectional: True
    hidden_size: 8
    num_layers: 2
    dropout: 0.1
    softmax_temp: 1    
  
  # smoothing: 0.1
  lr: 0.01
  weight_decay: 0.01

  scheduler:
    which: ''
    cosine_restart_after: 120
    const_factor: 0.97

vae_gp:
  
  cov_type: 'banded' # full, banded or diagonal for z
  
  rnn_encoder:
    bidirectional: True
    hidden_size: 8
    num_layers: 2
    dropout: 0.1
  
  post_rnn_linear:
    hidden_dims: []
    dropout: 0

  smoothing_sigma: 1
  kl_beta: 1
  weight_decay: 0.01

  lr: 0.01

  monotonic:
    use: False    
    nu_z: 5
    nu_g: 1
    coeff: 100

decoder:
  behavior_weight: 10

  stimulus_weight: 1
  choice_weight: 1
  
  # which: 'cnn_indi'
  which: ''
  train_decoder_after: 0
  
  cnn:
    # channels: [4, 4, 4, 4, 4, 4]
    channels: [4]
    kernel_size: 7
    dropout: 0.2
    lr: 0.01
    weight_decay: 0

  rnn:
    layers: 1
    hidden_dim: 8
    lr: 0.001
    dropout: 0.3  

  linear:
    hidden_dims: [8, 8]
    dropout: 0.1
    lr: 0.0003

  scheduler:
    which: ''
    cosine_restart_after: 120
    const_factor: 0.99

seed: 7

early_stop:
  patience: 25
  delta: 1
  test_every_new: 2

epochs: 1000
test_every: 20
plot_every: 5

batch_size: 192
optim_size: 192

num_samples_train: 50
num_samples_test: 20


z_prior:
  include: False
  weights: [100, 0]
  # means and stds multipled by number of bins  
  means: [0, 1]
  stds: [0.2, 1]
  learn: True
  prior_on_mean: False