{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import utils\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# train svm, lr\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution of Stimulus: 0.46875, Choice: 0.359375, Prev Choice: 0.453125\n",
      "Test distribution of Stimulus: 0.5454545454545454, Choice: 0.48484848484848486, Prev Choice: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/5kr9n8rj3t18qph0lvrgf3dw0000gn/T/ipykernel_66634/856997722.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  amp = torch.tensor([x[:, amp_idx] for x in behaviour_data_all], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "config = utils.read_config()\n",
    "# set seeds\n",
    "utils.set_seeds(config['seed'])\n",
    "behaviour_data_all, spikes, trial_indices = utils.load_dataset(config)\n",
    "# consider data from only t = -1\n",
    "# time_from = int(1/bin_len)\n",
    "# behaviour_data_all, spikes = [x[time_from:, :] for x in behaviour_data_all], [x[time_from:, :] for x in spikes]\n",
    "stim_idx, choice_idx, amp_idx, prev_choice_idx = 9, 3, 24, 6\n",
    "stim = [x[0, stim_idx] for x in behaviour_data_all]\n",
    "choice = [x[0, choice_idx] for x in behaviour_data_all]\n",
    "prev_choice = [x[0, prev_choice_idx] for x in behaviour_data_all]\n",
    "amp = torch.tensor([x[:, amp_idx] for x in behaviour_data_all], dtype=torch.float32)\n",
    "# normalize amp by max value\n",
    "amp = amp / amp.max()\n",
    "num_contacts = [np.sum(x[:, 15:19], axis=1) for x in behaviour_data_all]\n",
    "# concat them\n",
    "behaviour_data = np.stack((stim, choice, prev_choice), axis=1)\n",
    "# convert to torch tensors\n",
    "behaviour_data = np.array(behaviour_data)\n",
    "# behaviour_data = torch.tensor(behaviour_data, dtype=torch.float32)\n",
    "spikes = np.array(spikes)\n",
    "num_trials, time_bins, emissions_dim = spikes.shape\n",
    "# create dataloader with random sampling for training and testing\n",
    "# split data into training and testing\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test = train_test_split(behaviour_data, spikes, test_size=0.3, random_state=42)\n",
    "behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, amp_train, amp_test = train_test_split(behaviour_data, spikes, amp, test_size=0.2, random_state=7)\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, amp_train, amp_test = train_test_split(behaviour_data, spikes, amp, test_size=0.3, random_state=7)\n",
    "# further split test into test and val\n",
    "# behaviour_data_test, behaviour_data_val, spikes_test, spikes_val, amp_test, amp_val = train_test_split(behaviour_data_test, spikes_test, amp_test, test_size=0.5, random_state=7)\n",
    "trials_train, trials_test = len(behaviour_data_train), len(behaviour_data_test)\n",
    "# distribution of choice and stimulus in test\n",
    "print(\"Train distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_train[:, 0]), np.mean(behaviour_data_train[:, 1]), np.mean(behaviour_data_train[:, 2])))\n",
    "print(\"Test distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_test[:, 0]), np.mean(behaviour_data_test[:, 1]), np.mean(behaviour_data_test[:, 2])))\n",
    "# print(\"Val distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_val[:, 0]), np.mean(behaviour_data_val[:, 1]), np.mean(behaviour_data_val[:, 2])))\n",
    "# labels\n",
    "y_stim_train, y_stim_test = behaviour_data_train[:, 0], behaviour_data_test[:, 0]\n",
    "y_choice_train, y_choice_test = behaviour_data_train[:, 1], behaviour_data_test[:, 1]\n",
    "y_prev_choice_train, y_prev_choice_test = behaviour_data_train[:, 2], behaviour_data_test[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple models on spikes for upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test accuracy (stimulus): 0.566060606060606, C = 5\n",
      "Max test accuracy (choice): 0.6036363636363636, C = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SVM')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reshape(s):\n",
    "    # return s.reshape(s.shape[0], -1)\n",
    "    return s.reshape(-1, s.shape[-1])\n",
    "\n",
    "train_acc_stim, test_acc_stim = [], []\n",
    "train_acc_choice, test_acc_choice = [], []\n",
    "list_c = [0.1, 1, 2, 5, 10]\n",
    "for which_beh, y_train, y_test in [('stim', y_stim_train, y_stim_test), ('choice', y_choice_train, y_choice_test)]:\n",
    "    # repeat 25 times\n",
    "    y_train = np.repeat(y_train, 25)\n",
    "    y_test = np.repeat(y_test, 25)    \n",
    "    for c in list_c:\n",
    "        # train svm\n",
    "        # clf = SVC(C=c)\n",
    "        # clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "        clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)        \n",
    "        clf.fit(reshape(spikes_train), y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(reshape(spikes_test))\n",
    "        pred_train = clf.predict(reshape(spikes_train))\n",
    "        # calculate accuracy\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)\n",
    "        if which_beh == 'stim':\n",
    "            train_acc_stim.append(train_accuracy)\n",
    "            test_acc_stim.append(test_accuracy)            \n",
    "        else:\n",
    "            train_acc_choice.append(train_accuracy)\n",
    "            test_acc_choice.append(test_accuracy)\n",
    "    # # take best C and train on validation set\n",
    "    # if which_beh == 'stim':\n",
    "    #     best_c = list_c[np.argmax(test_acc_stim)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 0], pred_val)\n",
    "    #     print(\"Validation accuracy (stimulus): {}, C = {}\".format(val_accuracy, best_c))\n",
    "    # else:\n",
    "    #     best_c = list_c[np.argmax(test_acc_choice)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 1], pred_val)\n",
    "    #     print(\"Validation accuracy (choice): {}, C = {}\".format(val_accuracy, best_c))\n",
    "# plot\n",
    "plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_stim, label='Test (stimulus)')\n",
    "plt.plot(list_c, train_acc_choice, label='Train (choice)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_choice, label='Test (choice)')\n",
    "# print max test accuracy\n",
    "max_test_acc_stim = np.max(test_acc_stim)\n",
    "max_test_acc_choice = np.max(test_acc_choice)\n",
    "print(\"Max test accuracy (stimulus): {}, C = {}\".format(max_test_acc_stim, list_c[np.argmax(test_acc_stim)]))\n",
    "print(\"Max test accuracy (choice): {}, C = {}\".format(max_test_acc_choice, list_c[np.argmax(test_acc_choice)]))\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('SVM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus and Choice decoding from single/multiple bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sided_window = 2\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "# behavior = 'stimulus'\n",
    "behavior = 'choice'\n",
    "list_c = [0.5, 1, 5, 10]\n",
    "x = np.arange(25)/10 - 2\n",
    "if behavior == 'stimulus':\n",
    "    y_train, y_test = y_stim_train, y_stim_test\n",
    "else:\n",
    "    y_train, y_test = y_choice_train, y_choice_test\n",
    "for c in list_c:\n",
    "    train_acc, test_acc = [], []\n",
    "    for t in range(25):\n",
    "        # train svm\n",
    "        clf = SVC(C=c)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        x_train = spikes_train_[:, t: t+2*one_sided_window+1].reshape(spikes_train_.shape[0], -1)\n",
    "        x_test = spikes_test_[:, t: t+2*one_sided_window+1].reshape(spikes_test_.shape[0], -1)        \n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)        \n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "    # plot\n",
    "    # plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "    plt.plot(x, test_acc, label='C={}'.format(c))\n",
    "    # print max    \n",
    "    print(\"Max train accuracy ({}; C={}): {}\".format(behavior, c, np.max(train_acc)))\n",
    "    print(\"Max test accuracy ({}; C={}): {}\\n\".format(behavior, c, np.max(test_acc)))\n",
    "\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Test accuracy for different time bins for {}; window = {}'.format(behavior, one_sided_window*2+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "model = Model(config, input_dim=emissions_dim)\n",
    "print(model.arch_name)\n",
    "# folder_pth = 'results/dandi_sub-221CR_ses-20190515T160400/100_ms/'\n",
    "# folder_pth = 'results/dandi_sub-221CR_ses-20190515T160400/100_ms/'\n",
    "folder_pth = '/Users/mithileshvaidya/Code/VAE/revised/results/dandi_sub-221CR_ses-20190515T160400/100_ms/vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_10_[False, True, False]_3_entropy_None_seed_21cnn_0_1_None'\n",
    "# prefix = '1simplevae_'\n",
    "# prefix = '2vaegp_'\n",
    "# prefix = '3monotonicity_'\n",
    "# prefix = '3monotonicitybest_'\n",
    "prefix = ''\n",
    "# with open(folder_pth + prefix + model.arch_name + '/res.pkl', 'rb') as f:\n",
    "with open(folder_pth + '/all_results.pkl', 'rb') as f:\n",
    "    all_data = pickle.load(f)\n",
    "x_mu_train, z_mu_train, x_mu_test, z_mu_test = all_data[1], all_data[2], all_data[10], all_data[11]\n",
    "x_samp_train, z_samp_train = all_data[5], all_data[6]\n",
    "x_samp_test, z_samp_test = all_data[14], all_data[15]\n",
    "x_cov, z_cov = all_data[3], all_data[4]\n",
    "y_recon_train, y_recon_test = all_data[0], all_data[9]\n",
    "x_mu_train, x_mu_test = x_mu_train.reshape(trials_train, time_bins, -1), x_mu_test.reshape(trials_test, time_bins, -1)\n",
    "z_presoftmax_train, z_presoftmax_test = all_data[7], all_data[16]\n",
    "amp_train_pred, amp_test_pred = all_data[-2], all_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z_mu_train and z_sample_train for a random trial\n",
    "trial_idx = np.random.randint(trials_train)\n",
    "plt.figure()\n",
    "plt.plot(z_mu_train[trial_idx, :, 1], label='z_mu')\n",
    "plt.plot(z_presoftmax_train[trial_idx, :, 1], label='z_samp')\n",
    "plt.legend()\n",
    "plt.title('z_mu and z_sample for a random trial (train)')\n",
    "# plot x_mu_train and x_samp_train for a random trial\n",
    "plt.figure()\n",
    "plt.plot(x_mu_train[trial_idx, :, 1], label='x_mu')\n",
    "plt.plot(x_samp_train[trial_idx, :, 1], label='x_samp')\n",
    "plt.legend()\n",
    "plt.title('x_mu and x_sample for a random trial (train)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each latent z, zero out time bins where z is not the argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "* spikes: trials x bins x neurons\n",
    "* x: trials x bins x x_dim\n",
    "* z: trials x bins x 3/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_from = 'spikes' # spikes or mu\n",
    "# decoding_from = 'mu' # spikes or mu\n",
    "# Thresholding based on z to keep only relevant time bins\n",
    "z_dim = z_mu_train.shape[-1]\n",
    "argmax_z_train = np.argmax(z_mu_train, axis=2)\n",
    "argmax_z_test = np.argmax(z_mu_test, axis=2)\n",
    "\n",
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "y_train, y_test = y_choice_train, y_choice_test\n",
    "# y_train, y_test = y_prev_choice_train, y_prev_choice_test\n",
    "\n",
    "list_c = [0.1, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "for i in range(z_dim):\n",
    "    # set spikes where z is not i to 0\n",
    "    if decoding_from == 'spikes':\n",
    "        x_train, x_test = spikes_train.copy(), spikes_test.copy()\n",
    "    else:\n",
    "        x_train, x_test = x_mu_train.copy(), x_mu_test.copy()\n",
    "    x_train[argmax_z_train != i] = 0\n",
    "    x_test[argmax_z_test != i] = 0\n",
    "    # # take only first 10 time bins\n",
    "    # x_train, x_test = x_train[:, :10], x_test[:, :10]\n",
    "    # print number of bins kept\n",
    "    print(\"Number of time bins kept for z = {}: {}\".format(i, np.mean(argmax_z_train == i)))\n",
    "    for c in list_c:\n",
    "        # train svm        \n",
    "        clf = SVC(C=c)\n",
    "        clf.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test.reshape(x_test.shape[0], -1))\n",
    "        pred_train = clf.predict(x_train.reshape(x_train.shape[0], -1))\n",
    "        # calculate accuracy\n",
    "        test_accuracy = round(accuracy_score(y_test, pred_test), 3)\n",
    "        train_accuracy = round(accuracy_score(y_train, pred_train), 3)\n",
    "        print(\"C: {}, Train accuracy: {}, Test accuracy: {}\".format(c, train_accuracy, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each latent z, zero out time bins where z < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "y_train, y_test = y_choice_train, y_choice_test\n",
    "threshold = 0.4\n",
    "\n",
    "for i in range(z_dim):\n",
    "    # set spikes where z < 0.5 to 0\n",
    "    # x_train, x_test = spikes_train.copy(), spikes_test.copy()\n",
    "    x_train, x_test = x_mu_train.copy(), x_mu_test.copy()\n",
    "    x_train[z_mu_train[:, :, i] < threshold] = 0\n",
    "    x_test[z_mu_test[:, :, i] < threshold] = 0\n",
    "    # print number of bins kept\n",
    "    print(\"Number of time bins kept for z = {}: {}\".format(i, np.mean(z_mu_train[:, :, i] >= threshold)))\n",
    "    # train svm\n",
    "    clf = SVC(C=1)\n",
    "    clf.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
    "    # predict\n",
    "    pred_test = clf.predict(x_test.reshape(x_test.shape[0], -1))\n",
    "    # calculate accuracy\n",
    "    test_accuracy = accuracy_score(y_test, pred_test)\n",
    "    print(\"Test accuracy (stimulus) after thresholding z: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test on time bin surrounding peak z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_from = 'spikes' # spikes or mu\n",
    "# decoding_from = 'mu' # spikes or mu\n",
    "# Thresholding based on z to keep only relevant time bins\n",
    "z_dim = z_mu_train.shape[-1]\n",
    "x_dim = x_mu_train.shape[-1]\n",
    "\n",
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "y_train, y_test = y_choice_train, y_choice_test\n",
    "# y_train, y_test = y_prev_choice_train, y_prev_choice_test\n",
    "\n",
    "list_c = [0.1, 0.5, 1, 2, 5]\n",
    "one_sided_window = 1\n",
    "# concatenate spikes with one sided window on both sides with zeros\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "\n",
    "for i in range(z_dim):\n",
    "# for i in [1]:\n",
    "    # set spikes where z is not i to 0\n",
    "    if decoding_from == 'spikes':\n",
    "        x_train, x_test = spikes_train_.copy(), spikes_test_.copy()\n",
    "    else:\n",
    "        x_train = np.concatenate([np.zeros((len(x_mu_train), one_sided_window, x_dim)), x_mu_train, np.zeros((len(x_mu_train), one_sided_window, x_dim))], axis=1)\n",
    "        x_test = np.concatenate([np.zeros((len(x_mu_test), one_sided_window, x_dim)), x_mu_test, np.zeros((len(x_mu_test), one_sided_window, x_dim))], axis=1)        \n",
    "    # print(x_train.shape, x_test.shape)\n",
    "    # find time bin where z peaks\n",
    "    argmax_z_train = np.argmax(z_mu_train[:, :, i], axis=1)\n",
    "    # print(argmax_z_train)\n",
    "    argmax_z_test = np.argmax(z_mu_test[:, :, i], axis=1)    \n",
    "    # take one sided window\n",
    "    x_train = np.array([x[argmax_z_train[j]:argmax_z_train[j]+2*one_sided_window+1] for j, x in enumerate(x_train)]).reshape(x_train.shape[0], -1)\n",
    "    x_test = np.array([x[argmax_z_test[j]:argmax_z_test[j]+2*one_sided_window+1] for j, x in enumerate(x_test)]).reshape(x_test.shape[0], -1)\n",
    "    \n",
    "    for c in list_c:\n",
    "        # train svm        \n",
    "        clf = SVC(C=c)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        test_accuracy = round(accuracy_score(y_test, pred_test), 3)\n",
    "        train_accuracy = round(accuracy_score(y_train, pred_train), 3)\n",
    "        print(\"C: {}, Train accuracy: {}, Test accuracy: {}\".format(c, train_accuracy, test_accuracy))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter trials based on peak of z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(z):\n",
    "    # z is of shape trials x time_bins    \n",
    "    mask = z[:, :10].max(axis=1) > 0.5\n",
    "    return mask\n",
    "softmax = torch.nn.Softmax(dim=2)\n",
    "z_mu_train_s = softmax(torch.tensor(z_mu_train, dtype=torch.float32)).numpy()\n",
    "z_mu_test_s = softmax(torch.tensor(z_mu_test, dtype=torch.float32)).numpy()\n",
    "train_mask, test_mask = filter(z_mu_train_s[:, :, 1]), filter(z_mu_test_s[:, :, 1])\n",
    "# keep only these trials\n",
    "x_mu_train, x_mu_test = x_mu_train[train_mask], x_mu_test[test_mask]\n",
    "y_stim_train, y_stim_test = y_stim_train[train_mask], y_stim_test[test_mask]\n",
    "y_choice_train, y_choice_test = y_choice_train[train_mask], y_choice_test[test_mask]\n",
    "y_prev_choice_train, y_prev_choice_test = y_prev_choice_train[train_mask], y_prev_choice_test[test_mask]\n",
    "spikes_train, spikes_test = spikes_train[train_mask], spikes_test[test_mask]\n",
    "z_mu_train, z_mu_test = z_mu_train[train_mask], z_mu_test[test_mask]\n",
    "\n",
    "chance_choice = max(np.mean(y_choice_test), 1 - np.mean(y_choice_test))\n",
    "chance_stim = max(np.mean(y_stim_test), 1 - np.mean(y_stim_test))\n",
    "chance_prev_choice = max(np.mean(y_prev_choice_test), 1 - np.mean(y_prev_choice_test))\n",
    "\n",
    "print(\"Chance level for choice: {}\".format(chance_choice))\n",
    "print(\"Chance level for stimulus: {}\".format(chance_stim))\n",
    "print(\"Chance level for prev choice: {}\".format(chance_prev_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_mask.sum(), len(train_mask), test_mask.sum(), len(test_mask))\n",
    "# print all indices where mask is True\n",
    "# print(np.where(train_mask)[0])\n",
    "print(spikes_train.shape, y_choice_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding_from = 'spikes' # spikes or mu\n",
    "decoding_from = 'mu' # spikes or mu\n",
    "one_sided_window = 2\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "# spikes_train_ = np.concatenate([np.zeros((len(y_recon_train), one_sided_window, emissions_dim)), y_recon_train, np.zeros((len(y_recon_train), one_sided_window, emissions_dim))], axis=1)\n",
    "# spikes_test_ = np.concatenate([np.zeros((len(y_recon_test), one_sided_window, emissions_dim)), y_recon_test, np.zeros((len(y_recon_test), one_sided_window, emissions_dim))], axis=1)\n",
    "x = np.arange(25)/10 - 2\n",
    "colors = ['r', 'b']\n",
    "C = 1\n",
    "for i, (behave, y_train, y_test) in enumerate(zip(['current choice', 'prev choice'], [y_choice_train, y_prev_choice_train], [y_choice_test, y_prev_choice_test])):\n",
    "    train_acc, test_acc = [], []\n",
    "    for t in range(25):\n",
    "        # train svm\n",
    "        clf = SVC(C=C)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        if decoding_from == 'spikes':\n",
    "            x_train = spikes_train_[:, t: t+2*one_sided_window+1].reshape(spikes_train_.shape[0], -1)\n",
    "            x_test = spikes_test_[:, t: t+2*one_sided_window+1].reshape(spikes_test_.shape[0], -1)\n",
    "        else:\n",
    "            x_train = np.concatenate([np.zeros((len(x_mu_train), one_sided_window)), x_mu_train[:, :, 1], np.zeros((len(x_mu_train), one_sided_window))], axis=1)\n",
    "            x_test = np.concatenate([np.zeros((len(x_mu_test), one_sided_window)), x_mu_test[:, :, 1], np.zeros((len(x_mu_test), one_sided_window))], axis=1)        \n",
    "            x_train = x_train[:, t: t+2*one_sided_window+1].reshape(x_train.shape[0], -1)\n",
    "            x_test = x_test[:, t: t+2*one_sided_window+1].reshape(x_test.shape[0], -1)\n",
    "        \n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        # print(y_test.shape, pred_test.shape)\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)        \n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "    # plot\n",
    "    # plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "    plt.plot(x, test_acc, label=behave, color=colors[i])\n",
    "    # print max    \n",
    "    print(\"Max train accuracy ({}): {}\".format(behave, np.max(train_acc)))\n",
    "    print(\"Max test accuracy ({}): {}\\n\".format(behave, np.max(test_acc)))\n",
    "\n",
    "# plot chance accuracies\n",
    "plt.axhline(y=chance_choice, color='r', linestyle='--', label='Chance (choice)')\n",
    "plt.axhline(y=chance_prev_choice, color='b', linestyle='--', label='Chance (prev choice)')\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Test accuracy using x1 for different time bins with window = {}'.format(one_sided_window*2+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation to amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_pth + prefix + model.arch_name +'/subspaces_filtered.pkl', 'rb') as f:\n",
    "    lin_maps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1, mapping2, mapping3 = lin_maps[0], lin_maps[1], lin_maps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do linear regression of amplitudes on spikes\n",
    "# for all time bins\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_train, spikes_test, amp_train, amp_test\n",
    "# inputs\n",
    "z_softmax = torch.nn.Softmax(dim=2)\n",
    "z_mu_train_s = z_softmax(torch.tensor(z_mu_train, dtype=torch.float32)).numpy()\n",
    "z_mu_test_s = z_softmax(torch.tensor(z_mu_test, dtype=torch.float32)).numpy()\n",
    "# original spikes\n",
    "inp_train = spikes_train.reshape(-1, spikes_train.shape[-1])#  * z_mu_train[:, :, 1].flatten()\n",
    "inp_test = spikes_test.reshape(-1, spikes_test.shape[-1])# * z_mu_test[:, :, 1].flatten()\n",
    "# reconstructed\n",
    "# inp_train = y_recon_train.reshape(-1, y_recon_train.shape[-1])#  * z_mu_train[:, :, 1].flatten()\n",
    "# inp_test = y_recon_test.reshape(-1, y_recon_test.shape[-1])# * z_mu_test[:, :, 1].flatten()\n",
    "# x\n",
    "# inp_train = x_mu_train[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = x_mu_test[:, :, 0].flatten().reshape(-1, 1)\n",
    "# z\n",
    "# inp_train = z_mu_train[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = z_mu_test[:, :, 0].flatten().reshape(-1, 1)\n",
    "# softmax(z)\n",
    "# inp_train = z_mu_train_s[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = z_mu_test_s[:, :, 0].flatten().reshape(-1, 1)\n",
    "# x * z or x * softmax(z)\n",
    "# inp_train = (x_mu_train[:, :, 0] * z_mu_train_s[:, :, 0]).flatten().reshape(-1, 1)\n",
    "# inp_test = (x_mu_test[:, :, 0] * z_mu_test_s[:, :, 0]).flatten().reshape(-1, 1)\n",
    "# inp_train = (x_mu_train[:, :, 2] * z_mu_train_s[:, :, 2]).flatten().reshape(-1, 1)\n",
    "# inp_test = (x_mu_test[:, :, 2] * z_mu_test_s[:, :, 2]).flatten().reshape(-1, 1)\n",
    "# x * softmax(z) * linear map\n",
    "\n",
    "# print(x_mu_train[:, :, 0].shape, z_mu_train_s[:, :, 0].shape, lin_map.shape)\n",
    "\n",
    "# using all\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 1:2] @ c2.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:3] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:3] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# using just 0\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "\n",
    "# using rest but only 1 non null\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:3] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:3] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# 2 non-null\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# just z1\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# just z2\n",
    "# inp_train = ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# amplitudes\n",
    "# inp_train = amp_train_pred.flatten().reshape(-1, 1)\n",
    "# inp_test = amp_test_pred.flatten().reshape(-1, 1)\n",
    "\n",
    "# # apply softplus\n",
    "# inp_train = np.log(1 + np.exp(inp_train))\n",
    "# inp_test = np.log(1 + np.exp(inp_test))\n",
    "\n",
    "# targets\n",
    "amp_train_flat = np.array(amp_train).flatten()\n",
    "amp_test_flat = np.array(amp_test).flatten()\n",
    "\n",
    "# train linear regression\n",
    "reg = LinearRegression().fit(inp_train, amp_train_flat)\n",
    "# predict\n",
    "amp_pred_train = reg.predict(inp_train)\n",
    "amp_pred_test = reg.predict(inp_test)\n",
    "# calculate mse\n",
    "# mse_train = mean_squared_error(amp_train_flat, amp_pred_train)\n",
    "# mse_test = mean_squared_error(amp_test_flat, amp_pred_test)\n",
    "r2_train = r2_score(amp_train_flat, amp_pred_train)\n",
    "r2_test = r2_score(amp_test_flat, amp_pred_test)\n",
    "# print(\"Train MSE: {}, Test MSE: {}\".format(mse_train, mse_test))\n",
    "print(\"Train R2: {}, Test R2: {}\".format(r2_train, r2_test))\n",
    "\n",
    "# # correlation\n",
    "# corr_train = pearsonr(amp_train_flat, inp_train.flatten())\n",
    "# corr_test = pearsonr(amp_test_flat, inp_test.flatten())\n",
    "# print(\"Train correlation: {}, Test correlation: {}\".format(corr_train, corr_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = amp_pred_train.reshape(trials_train, time_bins)\n",
    "# reshaped = inp_train.reshape(trials_train, time_bins)\n",
    "# plot\n",
    "# plt.plot(np.mean(reshaped, axis=0), label='Predicted')\n",
    "# plt.plot(np.mean(amp_train, axis=0), label='True')\n",
    "trial_idx = np.random.randint(trials_train)\n",
    "# trial_idx = 23\n",
    "plt.plot(reshaped[trial_idx], label='Predicted')\n",
    "plt.plot(amp_train[trial_idx], label='True')\n",
    "plt.legend()\n",
    "plt.xlabel('Time bin')\n",
    "plt.title(\"full y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LR model for behavior prediction and plot weights for each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = spikes_train.reshape(-1, spikes_train.shape[-1])\n",
    "x_test = spikes_test.reshape(-1, spikes_test.shape[-1])\n",
    "y_train, y_test = amp_train_flat, amp_test_flat\n",
    "\n",
    "# x_train = spikes_train.reshape(spikes_train.shape[0], -1)\n",
    "# x_test = spikes_test.reshape(spikes_test.shape[0], -1)\n",
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "\n",
    "# linear regression\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "# reg = LogisticRegression(penalty='l1', C=1, solver='liblinear').fit(x_train, y_train)\n",
    "# accuracies\n",
    "train_accuracy = reg.score(x_train, y_train)\n",
    "test_accuracy = reg.score(x_test, y_test)\n",
    "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_accuracy, test_accuracy))\n",
    "# plot weights for each neuron\n",
    "coeffs = abs(reg.coef_)\n",
    "# plt.plot(coeffs)\n",
    "# reshape into time x neurons\n",
    "# coeffs = coeffs.reshape(-1, emissions_dim).mean(axis=0)\n",
    "print(coeffs)\n",
    "plt.plot(coeffs)\n",
    "\n",
    "# plt.xlabel('Neuron')\n",
    "# plt.ylabel('Weight')\n",
    "# plt.title('Weights for each neuron')\n",
    "# # sort weights in descending order of absolute value and print them\n",
    "sorted_weights = np.argsort(coeffs)[::-1]\n",
    "print(sorted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_weights, coeffs[sorted_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca on spikes\n",
    "from sklearn.decomposition import PCA\n",
    "print(spikes.shape)\n",
    "pca = PCA(n_components=14)\n",
    "pca.fit(spikes.reshape(-1, spikes.shape[-1]))\n",
    "# print cumulative explained variance\n",
    "print(pca.explained_variance_ratio_.cumsum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
