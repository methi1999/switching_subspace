{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import utils\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# train svm, lr\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "# set seeds\n",
    "utils.set_seeds(config['seed'])\n",
    "behaviour_data_all, spikes, trial_indices = utils.load_dataset(config)\n",
    "# consider data from only t = -1\n",
    "# time_from = int(1/bin_len)\n",
    "# behaviour_data_all, spikes = [x[time_from:, :] for x in behaviour_data_all], [x[time_from:, :] for x in spikes]\n",
    "stim_idx, choice_idx, amp_idx, prev_choice_idx = 9, 3, 24, 6\n",
    "stim = [x[0, stim_idx] for x in behaviour_data_all]\n",
    "choice = [x[0, choice_idx] for x in behaviour_data_all]\n",
    "prev_choice = [x[0, prev_choice_idx] for x in behaviour_data_all]\n",
    "amp = torch.tensor([x[:, amp_idx] for x in behaviour_data_all], dtype=torch.float32)\n",
    "# normalize amp by max value\n",
    "amp = amp / amp.max()\n",
    "num_contacts = [np.sum(x[:, 15:19], axis=1) for x in behaviour_data_all]\n",
    "# concat them\n",
    "behaviour_data = np.stack((stim, choice, prev_choice), axis=1)\n",
    "# convert to torch tensors\n",
    "behaviour_data = np.array(behaviour_data)\n",
    "# behaviour_data = torch.tensor(behaviour_data, dtype=torch.float32)\n",
    "spikes = np.array(spikes)\n",
    "num_trials, time_bins, emissions_dim = spikes.shape\n",
    "# create dataloader with random sampling for training and testing\n",
    "# split data into training and testing\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test = train_test_split(behaviour_data, spikes, test_size=0.3, random_state=42)\n",
    "behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, num_contacts_train, num_contacts_test = train_test_split(behaviour_data, spikes, num_contacts, test_size=0.2, random_state=7)\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, amp_train, amp_test = train_test_split(behaviour_data, spikes, amp, test_size=0.3, random_state=7)\n",
    "# further split test into test and val\n",
    "# behaviour_data_test, behaviour_data_val, spikes_test, spikes_val, amp_test, amp_val = train_test_split(behaviour_data_test, spikes_test, amp_test, test_size=0.5, random_state=7)\n",
    "trials_train, trials_test = len(behaviour_data_train), len(behaviour_data_test)\n",
    "# distribution of choice and stimulus in test\n",
    "print(\"Train distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_train[:, 0]), np.mean(behaviour_data_train[:, 1]), np.mean(behaviour_data_train[:, 2])))\n",
    "print(\"Test distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_test[:, 0]), np.mean(behaviour_data_test[:, 1]), np.mean(behaviour_data_test[:, 2])))\n",
    "# print(\"Val distribution of Stimulus: {}, Choice: {}, Prev Choice: {}\".format(np.mean(behaviour_data_val[:, 0]), np.mean(behaviour_data_val[:, 1]), np.mean(behaviour_data_val[:, 2])))\n",
    "# labels\n",
    "y_stim_train, y_stim_test = behaviour_data_train[:, 0], behaviour_data_test[:, 0]\n",
    "y_choice_train, y_choice_test = behaviour_data_train[:, 1], behaviour_data_test[:, 1]\n",
    "y_prev_choice_train, y_prev_choice_test = behaviour_data_train[:, 2], behaviour_data_test[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple models on spikes for upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(s, c):\n",
    "    # keep only those time bins where contact is made\n",
    "    x = []\n",
    "    for i in range(len(s)):\n",
    "        x.append(s[i, c[i] > 0])\n",
    "    return x\n",
    "\n",
    "train_ = reshape(spikes_train, num_contacts_train)\n",
    "test_ = reshape(spikes_test, num_contacts_test)\n",
    "train_acc_stim, test_acc_stim = [], []\n",
    "train_acc_choice, test_acc_choice = [], []\n",
    "list_c = [0.1, 1, 2, 5, 10]\n",
    "for which_beh, y_train, y_test in [('stim', y_stim_train, y_stim_test), ('choice', y_choice_train, y_choice_test)]:\n",
    "    # repeat 25 times\n",
    "    y_train_ = [y_train[i] for i in range(len(train_)) for _ in range(len(train_[i]))]\n",
    "    y_test_ = [y_test[i] for i in range(len(test_)) for _ in range(len(test_[i]))]\n",
    "    # stack all spikes and labels\n",
    "    spikes_train = np.vstack(train_)\n",
    "    spikes_test = np.vstack(test_)        \n",
    "    for c in list_c:\n",
    "        # train svm\n",
    "        # clf = SVC(C=c)\n",
    "        # clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "        clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)                \n",
    "        clf.fit(spikes_train, y_train_)\n",
    "        # predict\n",
    "        pred_test = clf.predict(spikes_test)\n",
    "        pred_train = clf.predict(spikes_train)\n",
    "        # calculate accuracy\n",
    "        test_accuracy = accuracy_score(y_test_, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train_, pred_train)\n",
    "        if which_beh == 'stim':\n",
    "            train_acc_stim.append(train_accuracy)\n",
    "            test_acc_stim.append(test_accuracy)            \n",
    "        else:\n",
    "            train_acc_choice.append(train_accuracy)\n",
    "            test_acc_choice.append(test_accuracy)\n",
    "    # # take best C and train on validation set\n",
    "    # if which_beh == 'stim':\n",
    "    #     best_c = list_c[np.argmax(test_acc_stim)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 0], pred_val)\n",
    "    #     print(\"Validation accuracy (stimulus): {}, C = {}\".format(val_accuracy, best_c))\n",
    "    # else:\n",
    "    #     best_c = list_c[np.argmax(test_acc_choice)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 1], pred_val)\n",
    "    #     print(\"Validation accuracy (choice): {}, C = {}\".format(val_accuracy, best_c))\n",
    "# plot\n",
    "plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_stim, label='Test (stimulus)')\n",
    "plt.plot(list_c, train_acc_choice, label='Train (choice)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_choice, label='Test (choice)')\n",
    "# print max test accuracy\n",
    "max_test_acc_stim = np.max(test_acc_stim)\n",
    "max_test_acc_choice = np.max(test_acc_choice)\n",
    "print(\"Max test accuracy (stimulus): {}, C = {}\".format(max_test_acc_stim, list_c[np.argmax(test_acc_stim)]))\n",
    "print(\"Max test accuracy (choice): {}, C = {}\".format(max_test_acc_choice, list_c[np.argmax(test_acc_choice)]))\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('SVM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(s):\n",
    "    # return s.reshape(s.shape[0], -1)\n",
    "    return s.reshape(-1, s.shape[-1])\n",
    "\n",
    "train_acc_stim, test_acc_stim = [], []\n",
    "train_acc_choice, test_acc_choice = [], []\n",
    "list_c = [0.1, 1, 2, 5, 10]\n",
    "for which_beh, y_train, y_test in [('stim', y_stim_train, y_stim_test), ('choice', y_choice_train, y_choice_test)]:\n",
    "    # repeat 25 times\n",
    "    y_train = np.repeat(y_train, 25)\n",
    "    y_test = np.repeat(y_test, 25)    \n",
    "    for c in list_c:\n",
    "        # train svm\n",
    "        # clf = SVC(C=c)\n",
    "        # clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "        clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)        \n",
    "        clf.fit(reshape(spikes_train), y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(reshape(spikes_test))\n",
    "        pred_train = clf.predict(reshape(spikes_train))\n",
    "        # calculate accuracy\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)\n",
    "        if which_beh == 'stim':\n",
    "            train_acc_stim.append(train_accuracy)\n",
    "            test_acc_stim.append(test_accuracy)            \n",
    "        else:\n",
    "            train_acc_choice.append(train_accuracy)\n",
    "            test_acc_choice.append(test_accuracy)\n",
    "    # # take best C and train on validation set\n",
    "    # if which_beh == 'stim':\n",
    "    #     best_c = list_c[np.argmax(test_acc_stim)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 0], pred_val)\n",
    "    #     print(\"Validation accuracy (stimulus): {}, C = {}\".format(val_accuracy, best_c))\n",
    "    # else:\n",
    "    #     best_c = list_c[np.argmax(test_acc_choice)]\n",
    "    #     clf = SVC(C=best_c)\n",
    "    #     clf.fit(spikes_train.reshape(spikes_train.shape[0], -1), y_train)\n",
    "    #     pred_val = clf.predict(spikes_val.reshape(spikes_val.shape[0], -1))\n",
    "    #     val_accuracy = accuracy_score(behaviour_data_val[:, 1], pred_val)\n",
    "    #     print(\"Validation accuracy (choice): {}, C = {}\".format(val_accuracy, best_c))\n",
    "# plot\n",
    "plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_stim, label='Test (stimulus)')\n",
    "plt.plot(list_c, train_acc_choice, label='Train (choice)', linestyle='--')\n",
    "plt.plot(list_c, test_acc_choice, label='Test (choice)')\n",
    "# print max test accuracy\n",
    "max_test_acc_stim = np.max(test_acc_stim)\n",
    "max_test_acc_choice = np.max(test_acc_choice)\n",
    "print(\"Max test accuracy (stimulus): {}, C = {}\".format(max_test_acc_stim, list_c[np.argmax(test_acc_stim)]))\n",
    "print(\"Max test accuracy (choice): {}, C = {}\".format(max_test_acc_choice, list_c[np.argmax(test_acc_choice)]))\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('SVM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus and Choice decoding from single/multiple bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sided_window = 2\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "# behavior = 'stimulus'\n",
    "behavior = 'choice'\n",
    "list_c = [0.5, 1, 5, 10]\n",
    "x = np.arange(25)/10 - 2\n",
    "if behavior == 'stimulus':\n",
    "    y_train, y_test = y_stim_train, y_stim_test\n",
    "else:\n",
    "    y_train, y_test = y_choice_train, y_choice_test\n",
    "for c in list_c:\n",
    "    train_acc, test_acc = [], []\n",
    "    for t in range(25):\n",
    "        # train svm\n",
    "        clf = SVC(C=c)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        x_train = spikes_train_[:, t: t+2*one_sided_window+1].reshape(spikes_train_.shape[0], -1)\n",
    "        x_test = spikes_test_[:, t: t+2*one_sided_window+1].reshape(spikes_test_.shape[0], -1)        \n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)        \n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "    # plot\n",
    "    # plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "    plt.plot(x, test_acc, label='C={}'.format(c))\n",
    "    # print max    \n",
    "    print(\"Max train accuracy ({}; C={}): {}\".format(behavior, c, np.max(train_acc)))\n",
    "    print(\"Max test accuracy ({}; C={}): {}\\n\".format(behavior, c, np.max(test_acc)))\n",
    "\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Test accuracy for different time bins for {}; window = {}'.format(behavior, one_sided_window*2+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "model = Model(config, input_dim=emissions_dim)\n",
    "print(model.arch_name)\n",
    "# folder_pth = 'results/dandi_sub-221CR_ses-20190515T160400/100_ms/'\n",
    "folder_pth = 'results/dandi_sub-221CR_ses-20190515T160400/100_ms/'\n",
    "# folder_pth = '/Users/mithileshvaidya/Code/VAE/revised/results/dandi_sub-221CR_ses-20190515T160400/100_ms/vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_10_[False, True, False]_3_entropy_None_seed_21cnn_0_1_None'\n",
    "# prefix = '1simplevae_'\n",
    "# prefix = '2vaegp_'\n",
    "# prefix = '3monotonicity_'\n",
    "# prefix = '3monotonicitybest_'\n",
    "prefix = ''\n",
    "with open(folder_pth + prefix + model.arch_name + '/res.pkl', 'rb') as f:\n",
    "# with open(folder_pth + '/all_results.pkl', 'rb') as f:\n",
    "    all_data = pickle.load(f)\n",
    "x_mu_train, z_mu_train, x_mu_test, z_mu_test = all_data[1], all_data[2], all_data[10], all_data[11]\n",
    "x_samp_train, z_samp_train = all_data[5], all_data[6]\n",
    "x_samp_test, z_samp_test = all_data[14], all_data[15]\n",
    "x_cov, z_cov = all_data[3], all_data[4]\n",
    "y_recon_train, y_recon_test = all_data[0], all_data[9]\n",
    "x_mu_train, x_mu_test = x_mu_train.reshape(trials_train, time_bins, -1), x_mu_test.reshape(trials_test, time_bins, -1)\n",
    "z_presoftmax_train, z_presoftmax_test = all_data[7], all_data[16]\n",
    "amp_train_pred, amp_test_pred = all_data[-2], all_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z_mu_train and z_sample_train for a random trial\n",
    "trial_idx = np.random.randint(trials_train)\n",
    "plt.figure()\n",
    "plt.plot(z_mu_train[trial_idx, :, 1], label='z_mu')\n",
    "plt.plot(z_presoftmax_train[trial_idx, :, 1], label='z_samp')\n",
    "plt.legend()\n",
    "plt.title('z_mu and z_sample for a random trial (train)')\n",
    "# plot x_mu_train and x_samp_train for a random trial\n",
    "plt.figure()\n",
    "plt.plot(x_mu_train[trial_idx, :, 1], label='x_mu')\n",
    "plt.plot(x_samp_train[trial_idx, :, 1], label='x_samp')\n",
    "plt.legend()\n",
    "plt.title('x_mu and x_sample for a random trial (train)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each latent z, zero out time bins where z is not the argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "* spikes: trials x bins x neurons\n",
    "* x: trials x bins x x_dim\n",
    "* z: trials x bins x 3/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_from = 'spikes' # spikes or mu\n",
    "# decoding_from = 'mu' # spikes or mu\n",
    "# Thresholding based on z to keep only relevant time bins\n",
    "z_dim = z_mu_train.shape[-1]\n",
    "argmax_z_train = np.argmax(z_mu_train, axis=2)\n",
    "argmax_z_test = np.argmax(z_mu_test, axis=2)\n",
    "\n",
    "y_train, y_test = y_stim_train, y_stim_test\n",
    "# y_train, y_test = y_choice_train, y_choice_test\n",
    "# y_train, y_test = y_prev_choice_train, y_prev_choice_test\n",
    "\n",
    "list_c = [0.1, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "for i in range(z_dim):\n",
    "    # set spikes where z is not i to 0\n",
    "    if decoding_from == 'spikes':\n",
    "        x_train, x_test = spikes_train.copy(), spikes_test.copy()\n",
    "    else:\n",
    "        x_train, x_test = x_mu_train.copy(), x_mu_test.copy()\n",
    "    x_train[argmax_z_train != i] = 0\n",
    "    x_test[argmax_z_test != i] = 0\n",
    "    # # take only first 10 time bins\n",
    "    # x_train, x_test = x_train[:, :10], x_test[:, :10]\n",
    "    # print number of bins kept\n",
    "    print(\"Number of time bins kept for z = {}: {}\".format(i, np.mean(argmax_z_train == i)))\n",
    "    for c in list_c:\n",
    "        # train svm        \n",
    "        clf = SVC(C=c)\n",
    "        clf.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test.reshape(x_test.shape[0], -1))\n",
    "        pred_train = clf.predict(x_train.reshape(x_train.shape[0], -1))\n",
    "        # calculate accuracy\n",
    "        test_accuracy = round(accuracy_score(y_test, pred_test), 3)\n",
    "        train_accuracy = round(accuracy_score(y_train, pred_train), 3)\n",
    "        print(\"C: {}, Train accuracy: {}, Test accuracy: {}\".format(c, train_accuracy, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each latent z, zero out time bins where z < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "y_train, y_test = y_choice_train, y_choice_test\n",
    "threshold = 0.4\n",
    "\n",
    "for i in range(z_dim):\n",
    "    # set spikes where z < 0.5 to 0\n",
    "    # x_train, x_test = spikes_train.copy(), spikes_test.copy()\n",
    "    x_train, x_test = x_mu_train.copy(), x_mu_test.copy()\n",
    "    x_train[z_mu_train[:, :, i] < threshold] = 0\n",
    "    x_test[z_mu_test[:, :, i] < threshold] = 0\n",
    "    # print number of bins kept\n",
    "    print(\"Number of time bins kept for z = {}: {}\".format(i, np.mean(z_mu_train[:, :, i] >= threshold)))\n",
    "    # train svm\n",
    "    clf = SVC(C=1)\n",
    "    clf.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
    "    # predict\n",
    "    pred_test = clf.predict(x_test.reshape(x_test.shape[0], -1))\n",
    "    # calculate accuracy\n",
    "    test_accuracy = accuracy_score(y_test, pred_test)\n",
    "    print(\"Test accuracy (stimulus) after thresholding z: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test on time bin surrounding peak z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_from = 'spikes' # spikes or mu\n",
    "# decoding_from = 'mu' # spikes or mu\n",
    "# Thresholding based on z to keep only relevant time bins\n",
    "z_dim = z_mu_train.shape[-1]\n",
    "x_dim = x_mu_train.shape[-1]\n",
    "\n",
    "y_train, y_test = y_stim_train, y_stim_test\n",
    "# y_train, y_test = y_choice_train, y_choice_test\n",
    "# y_train, y_test = y_prev_choice_train, y_prev_choice_test\n",
    "\n",
    "list_c = [0.1, 0.5, 1, 2, 5]\n",
    "one_sided_window = 1\n",
    "# concatenate spikes with one sided window on both sides with zeros\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "\n",
    "for i in range(z_dim):\n",
    "# for i in [1]:\n",
    "    # set spikes where z is not i to 0\n",
    "    if decoding_from == 'spikes':\n",
    "        x_train, x_test = spikes_train_.copy(), spikes_test_.copy()\n",
    "    else:\n",
    "        x_train = np.concatenate([np.zeros((len(x_mu_train), one_sided_window, x_dim)), x_mu_train, np.zeros((len(x_mu_train), one_sided_window, x_dim))], axis=1)\n",
    "        x_test = np.concatenate([np.zeros((len(x_mu_test), one_sided_window, x_dim)), x_mu_test, np.zeros((len(x_mu_test), one_sided_window, x_dim))], axis=1)        \n",
    "    # print(x_train.shape, x_test.shape)\n",
    "    # find time bin where z peaks\n",
    "    argmax_z_train = np.argmax(z_mu_train[:, :, i], axis=1)\n",
    "    # print(argmax_z_train)\n",
    "    argmax_z_test = np.argmax(z_mu_test[:, :, i], axis=1)    \n",
    "    # take one sided window\n",
    "    x_train = np.array([x[argmax_z_train[j]:argmax_z_train[j]+2*one_sided_window+1] for j, x in enumerate(x_train)]).reshape(x_train.shape[0], -1)\n",
    "    x_test = np.array([x[argmax_z_test[j]:argmax_z_test[j]+2*one_sided_window+1] for j, x in enumerate(x_test)]).reshape(x_test.shape[0], -1)\n",
    "    \n",
    "    for c in list_c:\n",
    "        # train svm        \n",
    "        clf = SVC(C=c)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        test_accuracy = round(accuracy_score(y_test, pred_test), 3)\n",
    "        train_accuracy = round(accuracy_score(y_train, pred_train), 3)\n",
    "        print(\"C: {}, Train accuracy: {}, Test accuracy: {}\".format(c, train_accuracy, test_accuracy))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter trials based on peak of z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(z):\n",
    "    # z is of shape trials x time_bins    \n",
    "    mask = z[:, :10].max(axis=1) > 0.5\n",
    "    return mask\n",
    "softmax = torch.nn.Softmax(dim=2)\n",
    "z_mu_train_s = softmax(torch.tensor(z_mu_train, dtype=torch.float32)).numpy()\n",
    "z_mu_test_s = softmax(torch.tensor(z_mu_test, dtype=torch.float32)).numpy()\n",
    "train_mask, test_mask = filter(z_mu_train_s[:, :, 1]), filter(z_mu_test_s[:, :, 1])\n",
    "# keep only these trials\n",
    "x_mu_train, x_mu_test = x_mu_train[train_mask], x_mu_test[test_mask]\n",
    "y_stim_train, y_stim_test = y_stim_train[train_mask], y_stim_test[test_mask]\n",
    "y_choice_train, y_choice_test = y_choice_train[train_mask], y_choice_test[test_mask]\n",
    "y_prev_choice_train, y_prev_choice_test = y_prev_choice_train[train_mask], y_prev_choice_test[test_mask]\n",
    "spikes_train, spikes_test = spikes_train[train_mask], spikes_test[test_mask]\n",
    "z_mu_train, z_mu_test = z_mu_train[train_mask], z_mu_test[test_mask]\n",
    "\n",
    "chance_choice = max(np.mean(y_choice_test), 1 - np.mean(y_choice_test))\n",
    "chance_stim = max(np.mean(y_stim_test), 1 - np.mean(y_stim_test))\n",
    "chance_prev_choice = max(np.mean(y_prev_choice_test), 1 - np.mean(y_prev_choice_test))\n",
    "\n",
    "print(\"Chance level for choice: {}\".format(chance_choice))\n",
    "print(\"Chance level for stimulus: {}\".format(chance_stim))\n",
    "print(\"Chance level for prev choice: {}\".format(chance_prev_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_mask.sum(), len(train_mask), test_mask.sum(), len(test_mask))\n",
    "# print all indices where mask is True\n",
    "# print(np.where(train_mask)[0])\n",
    "print(spikes_train.shape, y_choice_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding_from = 'spikes' # spikes or mu\n",
    "decoding_from = 'mu' # spikes or mu\n",
    "one_sided_window = 2\n",
    "spikes_train_ = np.concatenate([np.zeros((len(spikes_train), one_sided_window, emissions_dim)), spikes_train, np.zeros((len(spikes_train), one_sided_window, emissions_dim))], axis=1)\n",
    "spikes_test_ = np.concatenate([np.zeros((len(spikes_test), one_sided_window, emissions_dim)), spikes_test, np.zeros((len(spikes_test), one_sided_window, emissions_dim))], axis=1)\n",
    "# spikes_train_ = np.concatenate([np.zeros((len(y_recon_train), one_sided_window, emissions_dim)), y_recon_train, np.zeros((len(y_recon_train), one_sided_window, emissions_dim))], axis=1)\n",
    "# spikes_test_ = np.concatenate([np.zeros((len(y_recon_test), one_sided_window, emissions_dim)), y_recon_test, np.zeros((len(y_recon_test), one_sided_window, emissions_dim))], axis=1)\n",
    "x = np.arange(25)/10 - 2\n",
    "colors = ['r', 'b']\n",
    "C = 1\n",
    "for i, (behave, y_train, y_test) in enumerate(zip(['current choice', 'prev choice'], [y_choice_train, y_prev_choice_train], [y_choice_test, y_prev_choice_test])):\n",
    "    train_acc, test_acc = [], []\n",
    "    for t in range(25):\n",
    "        # train svm\n",
    "        clf = SVC(C=C)\n",
    "        # clf = LogisticRegression(penalty='l1', solver='liblinear', C=c)\n",
    "        if decoding_from == 'spikes':\n",
    "            x_train = spikes_train_[:, t: t+2*one_sided_window+1].reshape(spikes_train_.shape[0], -1)\n",
    "            x_test = spikes_test_[:, t: t+2*one_sided_window+1].reshape(spikes_test_.shape[0], -1)\n",
    "        else:\n",
    "            x_train = np.concatenate([np.zeros((len(x_mu_train), one_sided_window)), x_mu_train[:, :, 1], np.zeros((len(x_mu_train), one_sided_window))], axis=1)\n",
    "            x_test = np.concatenate([np.zeros((len(x_mu_test), one_sided_window)), x_mu_test[:, :, 1], np.zeros((len(x_mu_test), one_sided_window))], axis=1)        \n",
    "            x_train = x_train[:, t: t+2*one_sided_window+1].reshape(x_train.shape[0], -1)\n",
    "            x_test = x_test[:, t: t+2*one_sided_window+1].reshape(x_test.shape[0], -1)\n",
    "        \n",
    "        clf.fit(x_train, y_train)\n",
    "        # predict\n",
    "        pred_test = clf.predict(x_test)\n",
    "        pred_train = clf.predict(x_train)\n",
    "        # calculate accuracy\n",
    "        # print(y_test.shape, pred_test.shape)\n",
    "        test_accuracy = accuracy_score(y_test, pred_test)\n",
    "        train_accuracy = accuracy_score(y_train, pred_train)        \n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "    # plot\n",
    "    # plt.plot(list_c, train_acc_stim, label='Train (stimulus)', linestyle='--')\n",
    "    plt.plot(x, test_acc, label=behave, color=colors[i])\n",
    "    # print max    \n",
    "    print(\"Max train accuracy ({}): {}\".format(behave, np.max(train_acc)))\n",
    "    print(\"Max test accuracy ({}): {}\\n\".format(behave, np.max(test_acc)))\n",
    "\n",
    "# plot chance accuracies\n",
    "plt.axhline(y=chance_choice, color='r', linestyle='--', label='Chance (choice)')\n",
    "plt.axhline(y=chance_prev_choice, color='b', linestyle='--', label='Chance (prev choice)')\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Test accuracy using x1 for different time bins with window = {}'.format(one_sided_window*2+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation to amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_pth + prefix + model.arch_name +'/subspaces_filtered.pkl', 'rb') as f:\n",
    "    lin_maps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1, mapping2, mapping3 = lin_maps[0], lin_maps[1], lin_maps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do linear regression of amplitudes on spikes\n",
    "# for all time bins\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_train, spikes_test, amp_train, amp_test\n",
    "# inputs\n",
    "z_softmax = torch.nn.Softmax(dim=2)\n",
    "z_mu_train_s = z_softmax(torch.tensor(z_mu_train, dtype=torch.float32)).numpy()\n",
    "z_mu_test_s = z_softmax(torch.tensor(z_mu_test, dtype=torch.float32)).numpy()\n",
    "# original spikes\n",
    "inp_train = spikes_train.reshape(-1, spikes_train.shape[-1])#  * z_mu_train[:, :, 1].flatten()\n",
    "inp_test = spikes_test.reshape(-1, spikes_test.shape[-1])# * z_mu_test[:, :, 1].flatten()\n",
    "# reconstructed\n",
    "# inp_train = y_recon_train.reshape(-1, y_recon_train.shape[-1])#  * z_mu_train[:, :, 1].flatten()\n",
    "# inp_test = y_recon_test.reshape(-1, y_recon_test.shape[-1])# * z_mu_test[:, :, 1].flatten()\n",
    "# x\n",
    "# inp_train = x_mu_train[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = x_mu_test[:, :, 0].flatten().reshape(-1, 1)\n",
    "# z\n",
    "# inp_train = z_mu_train[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = z_mu_test[:, :, 0].flatten().reshape(-1, 1)\n",
    "# softmax(z)\n",
    "# inp_train = z_mu_train_s[:, :, 0].flatten().reshape(-1, 1)\n",
    "# inp_test = z_mu_test_s[:, :, 0].flatten().reshape(-1, 1)\n",
    "# x * z or x * softmax(z)\n",
    "# inp_train = (x_mu_train[:, :, 0] * z_mu_train_s[:, :, 0]).flatten().reshape(-1, 1)\n",
    "# inp_test = (x_mu_test[:, :, 0] * z_mu_test_s[:, :, 0]).flatten().reshape(-1, 1)\n",
    "# inp_train = (x_mu_train[:, :, 2] * z_mu_train_s[:, :, 2]).flatten().reshape(-1, 1)\n",
    "# inp_test = (x_mu_test[:, :, 2] * z_mu_test_s[:, :, 2]).flatten().reshape(-1, 1)\n",
    "# x * softmax(z) * linear map\n",
    "\n",
    "# print(x_mu_train[:, :, 0].shape, z_mu_train_s[:, :, 0].shape, lin_map.shape)\n",
    "\n",
    "# using all\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 1:2] @ c2.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:3] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:3] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# using just 0\n",
    "# inp_train = ((x_mu_train[:, :, 0:1] @ c0.T + b0) * z_mu_train_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 0:1] @ c0.T + b0) * z_mu_test_s[:, :, 0:1]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "\n",
    "# using rest but only 1 non null\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:3] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:3] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# 2 non-null\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0]) + ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# just z1\n",
    "# inp_train = ((x_mu_train[:, :, 1:2] @ c1.T + b1) * z_mu_train_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 1:2] @ c1.T + b1) * z_mu_test_s[:, :, 1:2]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# just z2\n",
    "# inp_train = ((x_mu_train[:, :, 2:4] @ c2.T + b2) * z_mu_train_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "# inp_test = ((x_mu_test[:, :, 2:4] @ c2.T + b2) * z_mu_test_s[:, :, 2:3]).flatten().reshape(-1, c0.shape[0])\n",
    "\n",
    "# amplitudes\n",
    "# inp_train = amp_train_pred.flatten().reshape(-1, 1)\n",
    "# inp_test = amp_test_pred.flatten().reshape(-1, 1)\n",
    "\n",
    "# # apply softplus\n",
    "# inp_train = np.log(1 + np.exp(inp_train))\n",
    "# inp_test = np.log(1 + np.exp(inp_test))\n",
    "\n",
    "# targets\n",
    "amp_train_flat = np.array(amp_train).flatten()\n",
    "amp_test_flat = np.array(amp_test).flatten()\n",
    "\n",
    "# train linear regression\n",
    "reg = LinearRegression().fit(inp_train, amp_train_flat)\n",
    "# predict\n",
    "amp_pred_train = reg.predict(inp_train)\n",
    "amp_pred_test = reg.predict(inp_test)\n",
    "# calculate mse\n",
    "# mse_train = mean_squared_error(amp_train_flat, amp_pred_train)\n",
    "# mse_test = mean_squared_error(amp_test_flat, amp_pred_test)\n",
    "r2_train = r2_score(amp_train_flat, amp_pred_train)\n",
    "r2_test = r2_score(amp_test_flat, amp_pred_test)\n",
    "# print(\"Train MSE: {}, Test MSE: {}\".format(mse_train, mse_test))\n",
    "print(\"Train R2: {}, Test R2: {}\".format(r2_train, r2_test))\n",
    "\n",
    "# # correlation\n",
    "# corr_train = pearsonr(amp_train_flat, inp_train.flatten())\n",
    "# corr_test = pearsonr(amp_test_flat, inp_test.flatten())\n",
    "# print(\"Train correlation: {}, Test correlation: {}\".format(corr_train, corr_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = amp_pred_train.reshape(trials_train, time_bins)\n",
    "# reshaped = inp_train.reshape(trials_train, time_bins)\n",
    "# plot\n",
    "# plt.plot(np.mean(reshaped, axis=0), label='Predicted')\n",
    "# plt.plot(np.mean(amp_train, axis=0), label='True')\n",
    "trial_idx = np.random.randint(trials_train)\n",
    "# trial_idx = 23\n",
    "plt.plot(reshaped[trial_idx], label='Predicted')\n",
    "plt.plot(amp_train[trial_idx], label='True')\n",
    "plt.legend()\n",
    "plt.xlabel('Time bin')\n",
    "plt.title(\"full y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LR model for behavior prediction and plot weights for each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = spikes_train.reshape(-1, spikes_train.shape[-1])\n",
    "x_test = spikes_test.reshape(-1, spikes_test.shape[-1])\n",
    "y_train, y_test = amp_train_flat, amp_test_flat\n",
    "\n",
    "# x_train = spikes_train.reshape(spikes_train.shape[0], -1)\n",
    "# x_test = spikes_test.reshape(spikes_test.shape[0], -1)\n",
    "# y_train, y_test = y_stim_train, y_stim_test\n",
    "\n",
    "# linear regression\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "# reg = LogisticRegression(penalty='l1', C=1, solver='liblinear').fit(x_train, y_train)\n",
    "# accuracies\n",
    "train_accuracy = reg.score(x_train, y_train)\n",
    "test_accuracy = reg.score(x_test, y_test)\n",
    "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_accuracy, test_accuracy))\n",
    "# plot weights for each neuron\n",
    "coeffs = abs(reg.coef_)\n",
    "# plt.plot(coeffs)\n",
    "# reshape into time x neurons\n",
    "# coeffs = coeffs.reshape(-1, emissions_dim).mean(axis=0)\n",
    "print(coeffs)\n",
    "plt.plot(coeffs)\n",
    "\n",
    "# plt.xlabel('Neuron')\n",
    "# plt.ylabel('Weight')\n",
    "# plt.title('Weights for each neuron')\n",
    "# # sort weights in descending order of absolute value and print them\n",
    "sorted_weights = np.argsort(coeffs)[::-1]\n",
    "print(sorted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_weights, coeffs[sorted_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca on spikes\n",
    "from sklearn.decomposition import PCA\n",
    "print(spikes.shape)\n",
    "pca = PCA(n_components=14)\n",
    "pca.fit(spikes.reshape(-1, spikes.shape[-1]))\n",
    "# print cumulative explained variance\n",
    "print(pca.explained_variance_ratio_.cumsum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
