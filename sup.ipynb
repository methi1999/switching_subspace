{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from model import Model\n",
    "import utils\n",
    "from early_stopping import EarlyStopping\n",
    "from priors import moving_average\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "# set seeds\n",
    "utils.set_seeds(config['seed'])\n",
    "# utils.set_seeds(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_data, spikes, trial_ids = utils.load_dataset(config)\n",
    "# consider data from only t = -1\n",
    "# time_from = int(1/bin_len)\n",
    "# behaviour_data, spikes = [x[time_from:, :] for x in behaviour_data], [x[time_from:, :] for x in spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx, choice_idx, amp_idx = 9, 3, 24\n",
    "stim = [x[0, stim_idx] for x in behaviour_data]\n",
    "choice = [x[0, choice_idx] for x in behaviour_data]\n",
    "amp = torch.tensor([x[:, amp_idx] for x in behaviour_data], dtype=torch.float32)\n",
    "# normalize amp by max value\n",
    "amp = amp / amp.max()\n",
    "num_contacts = [np.sum(x[:, 15:19], axis=1) for x in behaviour_data]\n",
    "# concat them\n",
    "behaviour_data = np.stack((stim, choice), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "behaviour_data = torch.tensor(behaviour_data, dtype=torch.long)\n",
    "# behaviour_data = torch.tensor(behaviour_data, dtype=torch.float32)\n",
    "spikes = torch.tensor(spikes, dtype=torch.float32)\n",
    "num_trials, time_bins, emissions_dim = np.array(spikes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader with random sampling for training and testing\n",
    "# split data into training and testing\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test = train_test_split(behaviour_data, spikes, test_size=0.3, random_state=42)\n",
    "behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, amp_train, amp_test = train_test_split(behaviour_data, spikes, amp, test_size=0.2, random_state=7)\n",
    "# create dataloaders\n",
    "train_dataset = TensorDataset(behaviour_data_train, spikes_train, amp_train)\n",
    "test_dataset = TensorDataset(behaviour_data_test, spikes_test, amp_test)\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution of Stimulus: 0.46875, Choice: 0.359375\n",
      "Test distribution of Stimulus: 0.5454545454545454, Choice: 0.48484848484848486\n"
     ]
    }
   ],
   "source": [
    "# distribution of choice and stimulus in test\n",
    "print(\"Train distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_train[:, 0].numpy()), np.mean(behaviour_data_train[:, 1].numpy())))\n",
    "print(\"Test distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_test[:, 0].numpy()), np.mean(behaviour_data_test[:, 1].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean firing rate of neurons in tran spikes\n",
    "neuron_bias = torch.mean(spikes_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if mps is available\n",
    "# device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')\n",
    "# print(device)\n",
    "# model = model.to(device)\n",
    "# spikes = spikes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (behavior_batch, spikes_batch, amp_batch) in enumerate(test_loader):\n",
    "            vae_pred, behavior_pred, amp_pred = model(spikes_batch, n_samples=20, use_mean_for_decoding=True)\n",
    "            # calculate loss\n",
    "            loss, loss_l = model.loss(np.inf, spikes_batch, behavior_batch, amp_batch, vae_pred, behavior_pred, amp_pred)\n",
    "            # l.append(loss_l[1])\n",
    "            test_loss += np.array(loss_l)            \n",
    "            # print(np.mean(l), np.std(l))\n",
    "    # divide loss by total number of samples in dataloader    \n",
    "    return test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log det: tensor(-74.5478) Inverse max:  tensor(63.9476) Covariance max:  tensor(0.5100)\n",
      "Number of trainable parameters in RNN: 2400\n",
      "Number of trainable parameters in Posterior Mean: 190\n",
      "Number of trainable parameters in Block Diagonal Z: 163\n",
      "Number of trainable parameters in Cov X: 217\n",
      "Loading weights\n",
      "Weights loaded\n",
      "Number of trainable parameters in VAE: 3217\n",
      "Using stimulus decoder\n",
      "Using choice decoder\n",
      "Scheduler not implemented for decoder\n",
      "Number of trainable parameters in behavior decoder: 132\n",
      "vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_10_[True, True, False]_3_entropy_None_seed_7cnn_0_1_None\n"
     ]
    }
   ],
   "source": [
    "config = utils.read_config()\n",
    "# create model and optimizer\n",
    "model = Model(config, input_dim=emissions_dim)\n",
    "# model = Model(config, input_dim=emissions_dim, neuron_bias=neuron_bias)\n",
    "# model = torch.compile(model)\n",
    "early_stop = EarlyStopping(patience=config['early_stop']['patience'], delta=config['early_stop']['delta'], trace_func=print)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=1, verbose=True, patience=5, factor=0.5)\n",
    "# print named parameters of model\n",
    "# print(\"Model's state_dict:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "print(model.arch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/2000], Train Loss: [991.79162598  20.62210846], Test Loss: [996.85266113  20.94688416], Best Loss: 1017.7995452880859\n",
      "Saved best\n",
      "Epoch [40/2000], Train Loss: [960.20349121  20.47255707], Test Loss: [969.70635986  20.84475899], Best Loss: 990.551118850708\n",
      "Saved best\n",
      "Epoch [60/2000], Train Loss: [951.21209717  20.13709259], Test Loss: [961.86712646  20.87112427], Best Loss: 982.7382507324219\n",
      "Saved best\n",
      "Epoch [80/2000], Train Loss: [946.15917969  20.33790207], Test Loss: [954.85333252  21.34300232], Best Loss: 976.1963348388672\n",
      "Saved best\n",
      "Epoch [100/2000], Train Loss: [941.41290283  20.28993225], Test Loss: [951.24072266  21.74073601], Best Loss: 972.9814586639404\n",
      "Saved best\n",
      "Epoch [120/2000], Train Loss: [938.01824951  20.09321594], Test Loss: [947.57659912  21.90181351], Best Loss: 969.4784126281738\n",
      "Saved best\n",
      "Epoch [140/2000], Train Loss: [934.49346924  20.03056335], Test Loss: [943.65002441  22.04200363], Best Loss: 965.6920280456543\n",
      "Saved best\n",
      "Epoch [160/2000], Train Loss: [930.55554199  19.57405663], Test Loss: [939.16534424  21.85692024], Best Loss: 961.0222644805908\n",
      "Saved best\n",
      "Epoch [180/2000], Train Loss: [924.52648926  18.54210281], Test Loss: [932.06134033  21.42088699], Best Loss: 953.4822273254395\n",
      "Saved best\n",
      "Epoch [200/2000], Train Loss: [916.4888916   18.34453773], Test Loss: [923.52612305  22.06729317], Best Loss: 945.5934162139893\n",
      "Saved best\n",
      "Epoch [220/2000], Train Loss: [909.5501709   16.78684235], Test Loss: [916.88635254  21.77108383], Best Loss: 938.6574363708496\n",
      "Saved best\n",
      "Epoch [240/2000], Train Loss: [903.67346191  15.7565403 ], Test Loss: [911.03790283  20.41252899], Best Loss: 931.4504318237305\n",
      "Saved best\n",
      "Epoch [260/2000], Train Loss: [900.00714111  14.65608501], Test Loss: [907.51013184  20.15052223], Best Loss: 927.6606540679932\n",
      "Saved best\n",
      "Epoch [280/2000], Train Loss: [896.89404297  13.60086918], Test Loss: [905.0645752   18.34331894], Best Loss: 923.4078941345215\n",
      "Epoch [300/2000], Train Loss: [894.87353516  12.75340748], Test Loss: [904.22875977  18.61919403], Best Loss: 923.4078941345215\n",
      "Saved best\n",
      "Epoch [302/2000], Train Loss: [894.79211426  12.65138054], Test Loss: [903.13458252  18.32061768], Best Loss: 921.4552001953125\n",
      "Epoch [320/2000], Train Loss: [894.07403564  10.64040947], Test Loss: [902.22479248  20.32577896], Best Loss: 921.4552001953125\n",
      "Epoch [322/2000], Train Loss: [893.57891846  10.74914932], Test Loss: [902.26269531  20.27031708], Best Loss: 921.4552001953125\n",
      "Epoch [324/2000], Train Loss: [893.12811279  10.93639565], Test Loss: [901.47064209  19.98521042], Best Loss: 921.4552001953125\n",
      "Epoch [326/2000], Train Loss: [893.83007812  10.10271645], Test Loss: [902.06646729  20.97496033], Best Loss: 921.4552001953125\n",
      "Epoch [328/2000], Train Loss: [893.04815674  10.56718063], Test Loss: [901.41070557  20.80369186], Best Loss: 921.4552001953125\n",
      "Epoch [330/2000], Train Loss: [892.98162842  10.74563313], Test Loss: [902.08013916  21.88454819], Best Loss: 921.4552001953125\n",
      "Epoch [332/2000], Train Loss: [893.18212891  10.37389755], Test Loss: [901.34857178  22.23101807], Best Loss: 921.4552001953125\n",
      "Epoch [334/2000], Train Loss: [893.17364502   9.95703888], Test Loss: [902.44622803  21.99897575], Best Loss: 921.4552001953125\n",
      "Epoch [336/2000], Train Loss: [892.71582031   9.69310188], Test Loss: [901.21307373  22.23692513], Best Loss: 921.4552001953125\n",
      "Epoch [338/2000], Train Loss: [892.65002441   9.31618118], Test Loss: [901.82867432  21.00321579], Best Loss: 921.4552001953125\n",
      "Epoch [340/2000], Train Loss: [892.94500732   9.22957611], Test Loss: [900.96209717  21.96401787], Best Loss: 921.4552001953125\n",
      "Epoch [342/2000], Train Loss: [892.74072266  10.15628433], Test Loss: [901.16412354  22.46172714], Best Loss: 921.4552001953125\n",
      "Epoch [344/2000], Train Loss: [892.35388184   9.91347408], Test Loss: [900.86608887  22.1291275 ], Best Loss: 921.4552001953125\n",
      "Epoch [346/2000], Train Loss: [892.21777344   9.13140965], Test Loss: [900.53936768  24.22569466], Best Loss: 921.4552001953125\n",
      "Epoch [348/2000], Train Loss: [892.31756592   8.63279343], Test Loss: [900.49536133  24.08549309], Best Loss: 921.4552001953125\n",
      "Epoch [350/2000], Train Loss: [892.06774902  10.46557236], Test Loss: [900.99017334  24.24665642], Best Loss: 921.4552001953125\n",
      "Epoch [352/2000], Train Loss: [892.26190186   8.49289703], Test Loss: [901.01959229  24.42433357], Best Loss: 921.4552001953125\n",
      "Epoch [354/2000], Train Loss: [892.07849121   8.74687958], Test Loss: [900.44226074  22.91587067], Best Loss: 921.4552001953125\n",
      "Epoch [356/2000], Train Loss: [891.49578857   9.02724075], Test Loss: [901.16040039  24.19495392], Best Loss: 921.4552001953125\n",
      "Epoch [358/2000], Train Loss: [891.58251953   8.58151817], Test Loss: [900.12860107  23.97363281], Best Loss: 921.4552001953125\n",
      "Epoch [360/2000], Train Loss: [891.49255371   8.11120605], Test Loss: [900.36779785  24.33079529], Best Loss: 921.4552001953125\n",
      "Epoch [362/2000], Train Loss: [891.42443848   8.7605896 ], Test Loss: [899.64849854  24.88911438], Best Loss: 921.4552001953125\n",
      "Epoch [364/2000], Train Loss: [891.21154785   7.6001215 ], Test Loss: [901.43457031  25.65481377], Best Loss: 921.4552001953125\n",
      "Epoch [366/2000], Train Loss: [891.38122559   7.94635963], Test Loss: [899.77880859  25.72340584], Best Loss: 921.4552001953125\n",
      "Epoch [368/2000], Train Loss: [891.14782715   8.17831421], Test Loss: [899.92175293  25.60328674], Best Loss: 921.4552001953125\n",
      "Epoch [370/2000], Train Loss: [891.00079346   8.35774803], Test Loss: [899.94897461  26.59795952], Best Loss: 921.4552001953125\n",
      "Epoch [372/2000], Train Loss: [891.38806152   7.89985371], Test Loss: [900.06323242  27.41486549], Best Loss: 921.4552001953125\n",
      "Epoch [374/2000], Train Loss: [890.43164062   7.958776  ], Test Loss: [899.01513672  26.53158951], Best Loss: 921.4552001953125\n",
      "Epoch [376/2000], Train Loss: [890.44726562   8.18780613], Test Loss: [899.26837158  26.91936302], Best Loss: 921.4552001953125\n",
      "Epoch [378/2000], Train Loss: [890.59606934   7.57400036], Test Loss: [899.48248291  25.92111015], Best Loss: 921.4552001953125\n",
      "Epoch [380/2000], Train Loss: [890.76837158   7.4460516 ], Test Loss: [899.30474854  26.22006989], Best Loss: 921.4552001953125\n",
      "Epoch [382/2000], Train Loss: [890.81463623   7.17875957], Test Loss: [898.74023438  26.43469429], Best Loss: 921.4552001953125\n",
      "Epoch [384/2000], Train Loss: [889.79724121   7.46801901], Test Loss: [898.87915039  27.52988243], Best Loss: 921.4552001953125\n",
      "Epoch [386/2000], Train Loss: [889.87091064   7.56953335], Test Loss: [898.78723145  28.39629555], Best Loss: 921.4552001953125\n",
      "Epoch [388/2000], Train Loss: [890.19335938   6.87826443], Test Loss: [899.23797607  28.78548241], Best Loss: 921.4552001953125\n",
      "Epoch [390/2000], Train Loss: [889.7265625    6.39991236], Test Loss: [898.56494141  26.30772209], Best Loss: 921.4552001953125\n",
      "Epoch [392/2000], Train Loss: [889.39630127   7.11303473], Test Loss: [898.94708252  27.47550201], Best Loss: 921.4552001953125\n",
      "Epoch [394/2000], Train Loss: [889.47363281   7.11222458], Test Loss: [898.14489746  28.51727104], Best Loss: 921.4552001953125\n",
      "Epoch [396/2000], Train Loss: [889.62615967   6.09725189], Test Loss: [898.65930176  29.22218704], Best Loss: 921.4552001953125\n",
      "Epoch [398/2000], Train Loss: [888.97705078   7.34693718], Test Loss: [898.01403809  29.47789764], Best Loss: 921.4552001953125\n",
      "Epoch [400/2000], Train Loss: [889.24395752   7.71241856], Test Loss: [898.33599854  28.28474808], Best Loss: 921.4552001953125\n",
      "Epoch [402/2000], Train Loss: [889.24005127   7.79817247], Test Loss: [898.17260742  29.67889023], Best Loss: 921.4552001953125\n",
      "Epoch [404/2000], Train Loss: [889.21191406   6.84099483], Test Loss: [898.69287109  27.71400261], Best Loss: 921.4552001953125\n",
      "Epoch [406/2000], Train Loss: [889.58044434   6.90283775], Test Loss: [898.58306885  28.48371696], Best Loss: 921.4552001953125\n",
      "Epoch [408/2000], Train Loss: [889.49963379   6.99018955], Test Loss: [897.80187988  30.01089096], Best Loss: 921.4552001953125\n",
      "Epoch [410/2000], Train Loss: [888.50061035   6.0875392 ], Test Loss: [898.64215088  27.46961784], Best Loss: 921.4552001953125\n",
      "Epoch [412/2000], Train Loss: [888.97839355   5.92840862], Test Loss: [897.14733887  28.16277313], Best Loss: 921.4552001953125\n",
      "Epoch [414/2000], Train Loss: [888.63317871   6.04741287], Test Loss: [897.75256348  28.74913216], Best Loss: 921.4552001953125\n",
      "Epoch [416/2000], Train Loss: [888.37188721   6.31570053], Test Loss: [897.00189209  28.06467438], Best Loss: 921.4552001953125\n",
      "Epoch [418/2000], Train Loss: [888.58630371   6.36110973], Test Loss: [897.66461182  28.38096619], Best Loss: 921.4552001953125\n",
      "Epoch [420/2000], Train Loss: [888.2010498    6.01060963], Test Loss: [896.59051514  29.52416611], Best Loss: 921.4552001953125\n",
      "Epoch [422/2000], Train Loss: [888.12432861   6.14134598], Test Loss: [896.56884766  29.4645977 ], Best Loss: 921.4552001953125\n",
      "Epoch [424/2000], Train Loss: [887.98419189   5.7915535 ], Test Loss: [896.46801758  30.17128944], Best Loss: 921.4552001953125\n",
      "Epoch [426/2000], Train Loss: [887.88885498   5.47183418], Test Loss: [896.16259766  31.27464867], Best Loss: 921.4552001953125\n",
      "Epoch [428/2000], Train Loss: [887.65301514   5.27322865], Test Loss: [896.16809082  31.20755768], Best Loss: 921.4552001953125\n",
      "Epoch [430/2000], Train Loss: [887.70587158   5.45028543], Test Loss: [896.28607178  30.46994209], Best Loss: 921.4552001953125\n",
      "Epoch [432/2000], Train Loss: [887.37304688   5.76408195], Test Loss: [896.45263672  31.03030968], Best Loss: 921.4552001953125\n",
      "Epoch [434/2000], Train Loss: [888.02624512   5.55052567], Test Loss: [895.65673828  31.30521393], Best Loss: 921.4552001953125\n",
      "Epoch [436/2000], Train Loss: [887.39434814   6.2312994 ], Test Loss: [895.49334717  31.41053391], Best Loss: 921.4552001953125\n",
      "Epoch [438/2000], Train Loss: [887.34143066   5.69285059], Test Loss: [896.75531006  30.17099953], Best Loss: 921.4552001953125\n",
      "Epoch [440/2000], Train Loss: [887.28399658   5.2440424 ], Test Loss: [894.85919189  30.51030731], Best Loss: 921.4552001953125\n",
      "Epoch [442/2000], Train Loss: [887.24725342   6.67780495], Test Loss: [895.2479248   29.97458076], Best Loss: 921.4552001953125\n",
      "Epoch [444/2000], Train Loss: [887.2767334    4.78277302], Test Loss: [895.11523438  31.5564537 ], Best Loss: 921.4552001953125\n",
      "Epoch [446/2000], Train Loss: [887.10070801   4.30729389], Test Loss: [895.74865723  31.71867371], Best Loss: 921.4552001953125\n",
      "Epoch [448/2000], Train Loss: [886.91699219   5.66877556], Test Loss: [894.79705811  30.47949791], Best Loss: 921.4552001953125\n",
      "Epoch [450/2000], Train Loss: [886.81933594   5.67538357], Test Loss: [895.33770752  31.02122116], Best Loss: 921.4552001953125\n",
      "Epoch [452/2000], Train Loss: [886.77178955   4.95509768], Test Loss: [894.50396729  34.31251526], Best Loss: 921.4552001953125\n",
      "Epoch [454/2000], Train Loss: [886.86981201   5.25921631], Test Loss: [894.29315186  32.21721649], Best Loss: 921.4552001953125\n",
      "Epoch [456/2000], Train Loss: [886.42169189   4.99124813], Test Loss: [894.21618652  32.18350601], Best Loss: 921.4552001953125\n",
      "Epoch [458/2000], Train Loss: [886.04211426   4.89509487], Test Loss: [894.05358887  32.28252792], Best Loss: 921.4552001953125\n",
      "Epoch [460/2000], Train Loss: [886.27716064   5.57488632], Test Loss: [894.72955322  32.40302658], Best Loss: 921.4552001953125\n",
      "Epoch [462/2000], Train Loss: [885.98614502   4.34767532], Test Loss: [893.48419189  31.91355133], Best Loss: 921.4552001953125\n",
      "Epoch [464/2000], Train Loss: [886.18768311   5.34493542], Test Loss: [893.63116455  34.49347687], Best Loss: 921.4552001953125\n",
      "Epoch [466/2000], Train Loss: [885.7388916    5.69458771], Test Loss: [893.30407715  34.2507515 ], Best Loss: 921.4552001953125\n",
      "Epoch [468/2000], Train Loss: [885.19207764   5.35909367], Test Loss: [893.65911865  32.66864395], Best Loss: 921.4552001953125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m         meds\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmax(only_test_loss[i\u001b[38;5;241m-\u001b[39mhalf_window:i\u001b[38;5;241m+\u001b[39mhalf_window]))\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(meds), train_losses, test_losses\n\u001b[0;32m---> 77\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# min_test_loss, train_losses, test_losses = train(model, test_loader)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [26], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, early_stop)\u001b[0m\n\u001b[1;32m     25\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(loss_l)            \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# backward pass            \u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print gradient of any weight\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if epoch > 10:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     print(model.behavior_decoder.conv_choice[1].weight.grad)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m optim_size:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "def train(model: Model, train_loader, val_loader, early_stop):    \n",
    "    test_every = config['test_every']    \n",
    "    train_decoder_after = config['decoder']['train_decoder_after']    \n",
    "    num_samples_train = config['num_samples_train']\n",
    "    optim_size = config['optim_size']\n",
    "    save_model = True    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # forward pass\n",
    "        # print(model.behavior_decoder.scheduler.get_last_lr())\n",
    "        # model.vae.scheduler.get_last_lr()\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        model.optim_zero_grad()\n",
    "        optim_counter = 0\n",
    "        for i, (behavior_batch, spikes_batch, amp_batch) in enumerate(train_loader):            \n",
    "            # behavior_batch = behavior_batch.long()\n",
    "            vae_pred, behavior_pred, amp_pred = model(spikes_batch, n_samples=num_samples_train, use_mean_for_decoding=False)            \n",
    "            optim_counter += len(behavior_batch)\n",
    "            # calculate loss\n",
    "            loss, loss_l = model.loss(epoch, spikes_batch, behavior_batch, amp_batch, vae_pred, behavior_pred, amp_pred)\n",
    "            epoch_loss += np.array(loss_l)            \n",
    "            # backward pass            \n",
    "            loss.backward()\n",
    "            \n",
    "            # print gradient of any weight\n",
    "            # if epoch > 10:\n",
    "            #     print(model.behavior_decoder.conv_choice[1].weight.grad)\n",
    "            if optim_counter >= optim_size:\n",
    "                model.optim_step(train_decoder = epoch >= train_decoder_after)\n",
    "                model.optim_zero_grad()\n",
    "                print(\"Stepping inside\")\n",
    "                optim_counter = 0\n",
    "        # do it for the rest        \n",
    "        model.optim_step(train_decoder = epoch >= train_decoder_after)\n",
    "        model.optim_zero_grad()\n",
    "        \n",
    "        # if epoch % 100 == 0:\n",
    "        #     # print lr of decoder\n",
    "        #     print(model.behavior_decoder.scheduler.get_last_lr())\n",
    "        train_losses.append((epoch, epoch_loss/len(train_loader)))\n",
    "        model.scheduler_step(step_decoder = epoch >= train_decoder_after)\n",
    "        # test loss\n",
    "        if (epoch+1) % test_every == 0:\n",
    "            test_loss = test(model, val_loader)\n",
    "            sum_test_loss = np.sum(test_loss)\n",
    "            # scheduler.step(sum_test_loss)\n",
    "            test_losses.append((epoch, test_loss))\n",
    "            early_stop(sum_test_loss, model, save_model=save_model, save_prefix='best')\n",
    "            model.save_model(save_prefix=str(epoch))\n",
    "            print('Epoch [{}/{}], Train Loss: {}, Test Loss: {}, Best Loss: {}'.format(epoch+1, config['epochs'], train_losses[-1][1], test_losses[-1][1], early_stop.best_score))\n",
    "            if early_stop.slow_down:\n",
    "                test_every = config['early_stop']['test_every_new']\n",
    "            else:\n",
    "                test_every = config['test_every']\n",
    "            if early_stop.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            \n",
    "    \n",
    "    only_test_loss = [np.sum(x[1]) for x in test_losses]\n",
    "    \n",
    "    # compute min test loss and return it    \n",
    "    # return np.min(only_test_loss), train_losses, test_losses\n",
    "    \n",
    "    # compute median of test loss in a window of 5\n",
    "    meds = []\n",
    "    half_window = 10\n",
    "    only_test_loss = [0]*(half_window) + only_test_loss + [0]*(half_window)\n",
    "    for i in range(half_window, len(only_test_loss)-half_window):\n",
    "        meds.append(np.max(only_test_loss[i-half_window:i+half_window]))\n",
    "    return np.min(meds), train_losses, test_losses\n",
    "\n",
    "_ = train(model, train_loader, test_loader, early_stop)\n",
    "# train model\n",
    "# min_test_loss, train_losses, test_losses = train(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_og, test_losses_og = train_losses[:], test_losses[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.prior_modules[0].plot_gaussian()\n",
    "# model.prior_modules[0].log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_loss_curve(model, config, train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort list by test loss\n",
    "sorted_loss = sorted(test_losses, key=lambda x: x[1][1], reverse=True) \n",
    "# extract first element after epoch 600\n",
    "sorted_loss = [(x[0], x[1][1]/100) for x in sorted_loss if x[0] > 100]\n",
    "print(sorted_loss[:2], sorted_loss[-10:])\n",
    "# print(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_model('best')\n",
    "# model.load_model(save_prefix='best', base_path='/Users/mithileshvaidya/Code/VAE/revised/results/dandi_sub-221CR_ses-20190515T160400/100_ms/3monotonicitybest_vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_20_[True, True, False]_3_entropy_None')\n",
    "# load model from epoch x\n",
    "# model.load_model('219')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_maps = model.vae.linear_maps\n",
    "c1, c2 = lin_maps[0].weight.detach().numpy(), lin_maps[1].weight.detach().numpy()\n",
    "print(c1, c2)\n",
    "# print(c1.T.dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2)))\n",
    "# with open(utils.model_store_path(config, model.arch_name) + '/subspaces_filtered.pkl', 'wb') as f:\n",
    "#     pickle.dump(lin_maps, f)\n",
    "# find cosine similarity of all pairs\n",
    "# print(c1.T.dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2)), c1.T.dot(c3)/(np.linalg.norm(c1)*np.linalg.norm(c3)), c2.T.dot(c3)/(np.linalg.norm(c2)*np.linalg.norm(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print cnn weights\n",
    "conv_weights = model.behavior_decoder.conv_stim[0].weight.detach().numpy()\n",
    "plt.imshow(conv_weights[:, 0, :])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bits per spike train: 0.27172091603279114, test: 0.23626384139060974, all: 0.2698090076446533\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'green', 'black', 'yellow', 'pink']\n",
    "# convert to numpy\n",
    "spikes_train_np = spikes_train.detach().numpy()\n",
    "spikes_test_np = spikes_test.detach().numpy()\n",
    "spikes_np = spikes.detach().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()        \n",
    "    # run on only test\n",
    "    vae_output, _, amp_out_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=True)  \n",
    "    y_recon_test, x_mu_test, z_mu_test, x_A_test, z_A_test, x_test, z_test, z_test_presoftmax, g_test = model.vae.extract_relevant(vae_output)\n",
    "    # run only on train\n",
    "    vae_output, _, amp_out_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=True)\n",
    "    y_recon_train, x_mu_train, z_mu_train, x_A_train, z_A_train, x_train, z_train, z_train_presoftmax, g_train = model.vae.extract_relevant(vae_output)\n",
    "    # run on both\n",
    "    vae_output, _, amp_out_all = model.forward(spikes, n_samples=1, use_mean_for_decoding=True)\n",
    "    y_recon_all, x_mu_all, z_mu_all, x_A_all, z_A_all, x_all, z_all, z_presoftmax_all, g_all = model.vae.extract_relevant(vae_output)\n",
    "\n",
    "# compute bits/spike\n",
    "bits_per_spike_train = utils.bits_per_spike(y_recon_train, spikes_train_np)\n",
    "bits_per_spike_test = utils.bits_per_spike(y_recon_test, spikes_test_np)\n",
    "bits_per_spike = utils.bits_per_spike(y_recon_all, spikes_np)\n",
    "# # show distribution of bits per spike\n",
    "# plt.hist(bits_per_spike_train, bins=50)\n",
    "# plt.xlabel('Bits/spike')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "# print('Bits per spike: {}'.format(bits_per_spike))\n",
    "print(\"Bits per spike train: {}, test: {}, all: {}\".format(np.sum(bits_per_spike_train), np.sum(bits_per_spike_test), np.sum(bits_per_spike)))\n",
    "\n",
    "to_write = (y_recon_train, x_mu_train, z_mu_train, x_A_train, z_A_train, x_train, z_train, z_train_presoftmax, g_train,\n",
    "            y_recon_test, x_mu_test, z_mu_test, x_A_test, z_A_test, x_test, z_test, z_test_presoftmax, g_test,\n",
    "            amp_out_train, amp_out_test)\n",
    "pth = os.path.join(utils.model_store_path(config, model.arch_name), 'res.pkl')\n",
    "with open(pth, 'wb') as f:\n",
    "    pickle.dump(to_write, f)\n",
    "# print(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = np.mean(z_A_train, axis=0)[10, :, :]\n",
    "# print(cov)\n",
    "# plt.imshow(np.linalg.inv(cov))\n",
    "fig, ax = plt.subplots(3, 1, figsize=(3, 9))\n",
    "for i in range(3):\n",
    "    cov = np.mean(z_A_train, axis=0)[:, :, i]    \n",
    "    im = ax[i].imshow(cov)\n",
    "    ax[i].set_title(\"Covariance of z{}\".format(i))\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PSTH of reconstructed and original data\n",
    "averaged_recon, averaged_original = y_recon.mean(axis=0), spikes_np.mean(axis=0)\n",
    "# stimulus and choice important\n",
    "common = [12, 14, 4, 31]\n",
    "stim_neurons = [15, 11, 33, 30]\n",
    "choice_neurons = [16, 2, 6, 8]\n",
    "# plot each in a 5x7 grid\n",
    "fig, axs = plt.subplots(5, 7, figsize=(12, 9))\n",
    "# set title of figure\n",
    "fig.suptitle('yellow: choice, green: stimulus, pink: common')\n",
    "for i in range(5):\n",
    "    for j in range(7):\n",
    "        neuron_idx = i*7+j        \n",
    "        axs[i, j].plot(averaged_recon[:, neuron_idx], label='recon', color='red')\n",
    "        axs[i, j].plot(averaged_original[:, neuron_idx], label='original', color='blue')\n",
    "        # no ticks\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "        # set title of plot to neuron index\n",
    "        # print only 2 decimal places        \n",
    "        axs[i, j].set_title('{}: {:.4f}'.format(neuron_idx, bits_per_spike_all[neuron_idx]))\n",
    "        # set background color of plot to green if neuron in choice\n",
    "        if neuron_idx in choice_neurons:\n",
    "            axs[i, j].set_facecolor('yellow')\n",
    "        # set background color of plot to red if neuron in stimulus\n",
    "        if neuron_idx in stim_neurons:\n",
    "            axs[i, j].set_facecolor('green')\n",
    "        # set background color of plot to blue if neuron in common\n",
    "        if neuron_idx in common:\n",
    "            axs[i, j].set_facecolor('pink')\n",
    "axs[0, 0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x318135360>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot trial averaged latent space\n",
    "# z, x = torch.nn.Softmax(dim=2)(mu[:, :, :model.vae.z_dim]).numpy(), mu[:, :, model.vae.z_dim:].numpy()\n",
    "z = z_all\n",
    "# z = z_mu_all\n",
    "# z = z_all_presoftmax\n",
    "# x = x_all\n",
    "x = x_mu_all\n",
    "z_std = np.std(z, axis=0)\n",
    "z_avg = np.mean(z, axis=0)\n",
    "# make x ticks of range 0.1 from -2 to 0.5\n",
    "bin_len = config['shape_dataset']['win_len']\n",
    "t = np.arange(-2, 0.5, bin_len)\n",
    "for i in range(z.shape[2]):\n",
    "    plt.plot(t, z_avg[:, i], label='z{}'.format(i), color=colors[i])    \n",
    "    plt.fill_between(t, z_avg[:, i]-z_std[:, i], z_avg[:, i]+z_std[:, i], alpha=0.3, color=colors[i])\n",
    "# plt.set_title('z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cont_latent(data, label, ax_id, linestyle):\n",
    "    num_latents = data.shape[1]\n",
    "    for i in range(num_latents):\n",
    "        axs[ax_id].plot(t, data[:, i], label='{}_x{}'.format(label, i),\n",
    "                        color=colors[i], linestyle=linestyle)    \n",
    "    \n",
    "# behave_data, x_data = behaviour_data_train, x_train\n",
    "# behave_data, x_data = behaviour_data_train, x_train*z_train\n",
    "behave_data, x_data = behaviour_data_test, x_test\n",
    "# behave_data, x_data = behaviour_data, x\n",
    "# group x for stimulus and choice\n",
    "stim, choice = behave_data[:, 0].numpy(), behave_data[:, 1].numpy()\n",
    "# group x for stimulus\n",
    "x_stim_left, x_stim_right = x_data[stim == 1].mean(axis=0), x_data[stim == 0].mean(axis=0)\n",
    "x_choice_left, x_choice_right = x_data[choice == 1].mean(axis=0), x_data[choice == 0].mean(axis=0)\n",
    "# plot x for stimulus and choice\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "plot_cont_latent(x_stim_left, 'stim left', 0, '-')\n",
    "plot_cont_latent(x_stim_right, 'stim right', 0, '-.')\n",
    "axs[0].set_title('x grouped by stimulus')\n",
    "axs[0].legend()\n",
    "\n",
    "plot_cont_latent(x_choice_left, 'choice left', 1, '-')\n",
    "plot_cont_latent(x_choice_right, 'choice right', 1, '-.')\n",
    "axs[1].set_title('x grouped by choice')\n",
    "axs[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x on 2d\n",
    "choice = behaviour_data[:, 1].numpy()\n",
    "# group x for stimulus\n",
    "x_choice_left, x_choice_right = x[choice == 1].mean(axis=0), x[choice == 0].mean(axis=0)\n",
    "z_choice_left, z_choice_right = z[choice == 1].mean(axis=0), z[choice == 0].mean(axis=0)\n",
    "# plot first 2 dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x_choice_left[:, 0], x_choice_left[:, 1], label='choice left', color='red')\n",
    "ax.plot(x_choice_right[:, 0], x_choice_right[:, 1], label='choice right', color='blue')\n",
    "# mark starting point\n",
    "ax.scatter(x_choice_left[0, 0], x_choice_left[0, 1], color='red')\n",
    "ax.scatter(x_choice_right[0, 0], x_choice_right[0, 1], color='blue')\n",
    "ax.legend()\n",
    "ax.set_title('x grouped by choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decoder\n",
    "nsamps = config['num_samples_train']\n",
    "with torch.no_grad():\n",
    "    model.eval()    \n",
    "    _, mu_train, A_train, z_train_all, x_train_all, _ = model.forward(spikes_train, n_samples=nsamps)\n",
    "    _, mu_test, A_test, z_test_all, x_test_all, _ = model.forward(spikes_test, n_samples=nsamps)\n",
    "\n",
    "z_train, x_train = z_train_all[:, :, 2:], x_train_all[:, :, 2:]\n",
    "z_test, x_test = z_test_all[:, :, 2:], x_test_all[:, :, 2:]\n",
    "# train the linear decoder for behavior\n",
    "# create linear decoder\n",
    "linear_decoder = decoder.CNNDecoderIndividual(config, [0, 1, 0])\n",
    "decoder_train_l, decoder_test_l = [], []\n",
    "for epoch in range(100):    \n",
    "    # forward pass        \n",
    "    linear_decoder.train()\n",
    "    behavior_pred = linear_decoder(x_train, z_train)\n",
    "    # print(behavior_pred)\n",
    "    # behavior_pred = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    # print(behavior_pred.shape, behaviour_data_train.shape)\n",
    "    loss = linear_decoder.loss(behavior_pred, behaviour_data_train, None)\n",
    "    # backward pass\n",
    "    linear_decoder.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    linear_decoder.optimizer.step()\n",
    "    epoch_loss = loss.item()    \n",
    "    decoder_train_l.append(epoch_loss)\n",
    "    # test loss\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        linear_decoder.eval()\n",
    "        test_pred = linear_decoder(x_test, z_test)\n",
    "        # behavior_pred = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "        test_loss = linear_decoder.loss(test_pred, behaviour_data_test, None).item()        \n",
    "        decoder_test_l.append(test_loss)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, num_epochs, decoder_train_l[-1], decoder_test_l[-1]))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    behavior_pred_train = linear_decoder(x_train, z_train).detach()\n",
    "    behavior_pred_test = linear_decoder(x_test, z_test).detach()\n",
    "    # behavior_pred_train = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    # behavior_pred_test = linear_decoder(mu_test[:, :, :2], mu_test[:, :, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stimulus train: 1.0, test: 0.6666666666666666\n",
      "Accuracy of choice train: 0.7734375, test: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "agg_pred_train, agg_pred_test = [], []\n",
    "agg_y_train, agg_y_test = [], []\n",
    "# convert to numpy\n",
    "y_train = behaviour_data_train.numpy()\n",
    "y_test = behaviour_data_test.numpy()\n",
    "# accuracy of stimulus and choice\n",
    "acc_stim_train, acc_stim_test = [], []\n",
    "acc_choice_train, acc_choice_test = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    behavior_pred_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=True)[1]\n",
    "    behavior_pred_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=True)[1]\n",
    "    # behavior_pred_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=False)[1]\n",
    "    # behavior_pred_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=False)[1]\n",
    "    # convert to numpy\n",
    "    # pred_train = behavior_pred_train.numpy() > 0\n",
    "    # pred_test = behavior_pred_test.numpy() > 0        \n",
    "    pred_train_stim = torch.argmax(behavior_pred_train[:, :2], dim=1).numpy()\n",
    "    pred_test_stim = torch.argmax(behavior_pred_test[:, :2], dim=1).numpy()\n",
    "    pred_train_choice = torch.argmax(behavior_pred_train[:, 2:4], dim=1).numpy()\n",
    "    pred_test_choice = torch.argmax(behavior_pred_test[:, 2:4], dim=1).numpy()    \n",
    "    # compute accuracy        \n",
    "    accuracy_train_stim = accuracy_score(y_train[:, 0], pred_train_stim)\n",
    "    accuracy_test_stim = accuracy_score(y_test[:, 0], pred_test_stim)        \n",
    "    # do the same for choice\n",
    "    accuracy_train_choice = accuracy_score(y_train[:, 1], pred_train_choice)\n",
    "    accuracy_test_choice = accuracy_score(y_test[:, 1], pred_test_choice)    \n",
    "# print accuracy\n",
    "print(\"Accuracy of stimulus train: {}, test: {}\".format(accuracy_train_stim, accuracy_test_stim))\n",
    "print(\"Accuracy of choice train: {}, test: {}\".format(accuracy_train_choice, accuracy_test_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random trial\n",
    "stim, choice = behaviour_data[:, 0].numpy(), behaviour_data[:, 1].numpy()\n",
    "amp_pred_ = amp_out_all.numpy()\n",
    "# examine a random trial\n",
    "trial_idx = np.random.randint(len(z))\n",
    "# trial_idx = 87\n",
    "# plot_g = False\n",
    "plot_g = True\n",
    "# trial_idx = 1\n",
    "# plot z and x\n",
    "# z = g_train\n",
    "if plot_g:\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(5, 8))\n",
    "else:\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(5, 8))\n",
    "# plot z\n",
    "# apply softmax\n",
    "# z[trial_idx, :] = np.exp(z[trial_idx, :])/np.sum(np.exp(z[trial_idx, :]), axis=1)[:, None]\n",
    "bin_len = config['shape_dataset']['win_len']\n",
    "t = np.arange(-2, 0.5, bin_len)\n",
    "axs[0].plot(t, z[trial_idx, :, 0], label='z0', marker='o', color=colors[0])\n",
    "axs[0].plot(t, z[trial_idx, :, 1], label='z1', marker='o', color=colors[1])\n",
    "axs[0].plot(t, z[trial_idx, :, 2], label='z2', marker='o', color=colors[2])\n",
    "axs[0].set_title('z for a random trial:'+str(trial_idx))\n",
    "# axs[0].set_ylim(0, 1)\n",
    "axs[0].legend()\n",
    "axs[0].set_xticks([])\n",
    "# plot num contacts\n",
    "axs[1].plot(t, num_contacts[trial_idx], marker='o', label='num contacts')\n",
    "axs[1].set_title('num contacts and amplitude of whisk')\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_ylabel('Num contacts')\n",
    "axs[1].legend(loc='upper left')\n",
    "# plot on right y axis\n",
    "ax2 = axs[1].twinx()\n",
    "ax2.plot(t, amp[trial_idx], marker='o', label='amplitude y', color='red')\n",
    "# ax2.plot(t, amp_pred_[trial_idx], marker='o', label='amplitude pred', color='green')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "\n",
    "# # plot time bin distribution\n",
    "# tbd = misc_all[2]\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 0], label='z0', marker='o')\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 1], label='z1', marker='o')\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 2], label='z2', marker='o')\n",
    "# axs[2].set_title('Softmax output of z before computing peak')\n",
    "# plot x\n",
    "axs[2].plot(t, x[trial_idx, :, 0], label='x0', marker='o', color=colors[0])\n",
    "axs[2].plot(t, x[trial_idx, :, 1], label='x1', marker='o', color=colors[1])\n",
    "axs[2].plot(t, x[trial_idx, :, 2], label='x2', marker='o', color=colors[2])\n",
    "# axs[2].plot(t, x[trial_idx, :, 3], label='x3', marker='o', color=colors[3])\n",
    "# axs[2].plot(t, x[trial_idx, :, 4], label='x4', marker='o', color=colors[4])\n",
    "# axs[2].plot(t, x[trial_idx, :, 5], label='x5', marker='o', color=colors[5])\n",
    "axs[2].set_title('x, stimulus: {}, choice: {}'.format(stim[trial_idx].astype(int), choice[trial_idx].astype(int)))\n",
    "\n",
    "if plot_g:\n",
    "    # plot g\n",
    "    def dt(x):\n",
    "        # pad with zeros on both side. x is of shape (t,)\n",
    "        x = np.concatenate((np.zeros((1,)), x, np.zeros((1,))), axis=0)\n",
    "        # compute difference\n",
    "        centred = (x[2:] - x[:-2])/2\n",
    "        # forward\n",
    "        forward = x[2:] - x[1:-1]\n",
    "        # backward\n",
    "        backward = x[1:-1] - x[:-2]        \n",
    "        return forward\n",
    "    g = g_all\n",
    "    axs[3].plot(t, g[trial_idx, :, 0], label='g0', marker='o')\n",
    "    axs[3].plot(t, g[trial_idx, :, 1], label='g1', marker='o')\n",
    "    # axs[3].plot(t, g[trial_idx, :, 2], label='g2', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 0]), label='dg0', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 1]), label='dg1', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 2]), label='dg2', marker='o')\n",
    "    axs[3].set_title('g, stimulus: {}, choice: {}'.format(stim[trial_idx].astype(int), choice[trial_idx].astype(int)))\n",
    "    # axs[3].set_ylim(-2, 2)\n",
    "    axs[3].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sklearn logistic regression model for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def reshape(x, y):\n",
    "    trials, time, dim = x.shape\n",
    "    # x = x[:, -5:-4, :]\n",
    "    return x.reshape(trials, -1), y\n",
    "\n",
    "stim_choice = 0\n",
    "\n",
    "x_train_baseline, y_train_baseline = reshape(spikes_train, behaviour_data_train)\n",
    "x_test_baseline, y_test_baseline = reshape(spikes_test, behaviour_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "log_reg = LogisticRegression(penalty='l1', C=1, solver='liblinear', verbose=1)\n",
    "# log_reg = SVC()\n",
    "log_reg.fit(x_train_baseline, y_train_baseline[:, stim_choice])\n",
    "# test accuracy\n",
    "accuracy_train = accuracy_score(y_train_baseline[:, stim_choice], log_reg.predict(x_train_baseline))\n",
    "accuracy_test = accuracy_score(y_test_baseline[:, stim_choice], log_reg.predict(x_test_baseline))\n",
    "print('Logistic Regression Accuracy - train: {:.4f}, test: {:.4f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Define logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(875, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = LogisticRegressionModel()\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x_train_baseline)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, y_train_baseline[:, stim_choice:stim_choice+1])\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    with torch.no_grad():    \n",
    "        predicted_prob = model(x_test_baseline)\n",
    "        test_losses.append(criterion(predicted_prob, y_test_baseline[:, stim_choice:stim_choice+1]).item())\n",
    "        predicted_class = (predicted_prob >= 0.5).float()\n",
    "        accuracy = (predicted_class == y_test_baseline[:, stim_choice:stim_choice+1]).float().mean()\n",
    "print(f'Accuracy: {accuracy.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg coeff\n",
    "# plot coefficients in a 2d grid\n",
    "# c = log_reg.coef_.reshape(-1, 25)\n",
    "# plt.imshow(c)\n",
    "\n",
    "# plot nn coefficients\n",
    "c = model.linear.weight.detach().numpy().reshape(-1, 25)\n",
    "plt.imshow(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and standard deviation of decoding loss over trials\n",
    "model.eval()\n",
    "# print(\"Total models to study:\", len(test_losses[:10] + test_losses[10::20]))\n",
    "print(\"Total models to study:\", len(test_losses))\n",
    "test_losses_aggregated = []\n",
    "z_agg, x_agg = [], []\n",
    "cov_norm = []\n",
    "cnn_weights = []\n",
    "decoding_runs = 50\n",
    "# for epoch, _ in test_losses[:10] + test_losses[10::20]:\n",
    "for epoch, _ in test_losses:\n",
    "    # print(epoch)\n",
    "    # if epoch != 331:\n",
    "    #     continue\n",
    "    model.load_model(str(epoch))\n",
    "    cur_epoch_loss = []\n",
    "    cur_epoch_z, cur_epoch_x = [], []\n",
    "    with torch.no_grad():\n",
    "        cov_norm_current = []\n",
    "        for _ in range(decoding_runs):\n",
    "            test_loss = []\n",
    "            cur_run_z, cur_run_x = [], []\n",
    "            for _, (behavior_batch, spikes_batch) in enumerate(test_loader):\n",
    "                y_recon, mu, A, z, x, behavior_batch_pred = model(spikes_batch, n_samples=1, use_mean_for_decoding=False)\n",
    "                behavior_loss = model.behavior_decoder.loss(behavior_batch_pred, behavior_batch, z, reduction='none')                \n",
    "                test_loss.append(behavior_loss)\n",
    "                cur_run_z.append(z[:, :, 0])\n",
    "                cur_run_x.append(x[:, :, 0])\n",
    "                cov_norm_current.append(np.linalg.norm(A.numpy()))\n",
    "            # stack horizontally and take mean across samples\n",
    "            test_loss = torch.mean(torch.cat(test_loss, dim=0), dim=0).item()\n",
    "            cur_epoch_loss.append(test_loss)\n",
    "            # stack z and x\n",
    "            z_stacked, x_stacked = torch.cat(cur_run_z, dim=0), torch.cat(cur_run_x, dim=0)            \n",
    "            cur_epoch_z.append(z_stacked)\n",
    "            cur_epoch_x.append(x_stacked)\n",
    "        \n",
    "        test_losses_aggregated.append((epoch, np.mean(cur_epoch_loss), np.std(cur_epoch_loss)))\n",
    "        # compute std for z and x\n",
    "        z_std, x_std = torch.std(torch.stack(cur_epoch_z), dim=0), torch.std(torch.stack(cur_epoch_x), dim=0)        \n",
    "        \n",
    "        z_agg.append((epoch, z_std.mean().item()))\n",
    "        x_agg.append((epoch, x_std.mean().item()))\n",
    "        # cov norm\n",
    "        cov_norm.append((epoch, np.mean(cov_norm_current)))\n",
    "        # cnn weights\n",
    "        cnn_weights.append((epoch, deepcopy(model.behavior_decoder.conv_stim), deepcopy(model.behavior_decoder.conv_choice)))        \n",
    "# # plot histogram\n",
    "# plt.hist(test_loss.numpy(), range=(0, 7), bins=50, density=True)\n",
    "# plt.xlabel('Cross entropy loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Test decoding loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean and std of test loss\n",
    "test_losses_plot = np.array(test_losses_aggregated)\n",
    "# plt.errorbar(test_losses_plot[:, 0], test_losses_plot[:, 1], yerr=test_losses_plot[:, 2])\n",
    "# print(test_losses_plot)\n",
    "plt.plot(test_losses_plot[:, 0], test_losses_plot[:, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross entropy loss')\n",
    "plt.title('Test decoding loss mean and std over 200 runs at various epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x and z\n",
    "print(z_agg)\n",
    "z_agg_plot = np.array(z_agg)\n",
    "x_agg_plot = np.array(x_agg)\n",
    "plt.plot(z_agg_plot[:, 0], z_agg_plot[:, 1], label='z')\n",
    "plt.plot(x_agg_plot[:, 0], x_agg_plot[:, 1], label='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Standard deviation')\n",
    "plt.title('Standard deviation of z and x over 200 runs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot norm of covariance\n",
    "cov_norm_plot = np.array(cov_norm)\n",
    "plt.plot(cov_norm_plot[:, 0], cov_norm_plot[:, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Norm of covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine particular examples\n",
    "# get mean and standard deviation of decoding loss over trials\n",
    "model.eval()\n",
    "print(\"Total models to study:\", len(test_losses))\n",
    "test_losses_aggregated = []\n",
    "decoding_runs = 100\n",
    "for epoch, _ in test_losses[:10] + test_losses[10::20]:\n",
    "    # print(epoch)\n",
    "    model.load_model(str(epoch))\n",
    "    cur_epoch_loss = []    \n",
    "    with torch.no_grad():        \n",
    "        for _ in range(decoding_runs):\n",
    "            test_loss = []\n",
    "            cur_run_z, cur_run_x = [], []\n",
    "            for _, (behavior_batch, spikes_batch) in enumerate(test_loader):\n",
    "                y_recon, (mu, A), (z, x), behavior_batch_pred = model(spikes_batch)\n",
    "                behavior_loss = model.behavior_decoder.loss(behavior_batch_pred, behavior_batch, z, reduction='none')                \n",
    "                test_loss.append(behavior_loss)                \n",
    "            # stack horizontally and take mean across samples\n",
    "            test_loss = torch.cat(test_loss, dim=0)\n",
    "            cur_epoch_loss.append(test_loss)\n",
    "        # stack the losses across decoding runs\n",
    "        cur_epoch_loss = torch.stack(cur_epoch_loss, dim=0)\n",
    "        # compute mean and std of epoch loss across decoding runs\n",
    "        m, s = torch.mean(cur_epoch_loss, dim=0).numpy(), torch.std(cur_epoch_loss, dim=0).numpy()        \n",
    "        test_losses_aggregated.append((epoch, m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(15):\n",
    "    epochs = [x[0] for x in test_losses_aggregated]\n",
    "    losses = [x[2][idx] for x in test_losses_aggregated]\n",
    "    plt.plot(epochs, losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross entropy loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot norm of change in CNN weights over time\n",
    "cnn_idx = 2\n",
    "base_cnn = cnn_weights[0][cnn_idx]\n",
    "layers_to_study = [(x, base_cnn[x].__module__.split('.')[-1]) for x in range(len(base_cnn)) if isinstance(base_cnn[x], torch.nn.Conv1d) or isinstance(base_cnn[x], torch.nn.BatchNorm1d)]\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "for layer_idx, name in layers_to_study:    \n",
    "    change_in_norms = []\n",
    "    for i, (epoch, _, cur_cnn) in enumerate(cnn_weights):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        cur_weight = cur_cnn[layer_idx].weight.detach().numpy()\n",
    "        prev_epoch_weights = cnn_weights[i-1][cnn_idx][layer_idx].weight.detach().numpy()        \n",
    "        change_in_norm = np.linalg.norm(cur_weight - prev_epoch_weights)        \n",
    "        # normalize by total number of weights        \n",
    "        change_in_norm /= cur_weight.size\n",
    "        change_in_norms.append((epoch, change_in_norm))\n",
    "    change_in_norms = np.array(change_in_norms)    \n",
    "    ax1.plot(change_in_norms[:, 0], change_in_norms[:, 1], label=name)\n",
    "\n",
    "# plot test_losses_og \n",
    "decoding_loss_only = np.array([(x[0], x[1][1]) for x in test_losses_og])\n",
    "ax2.plot(decoding_loss_only[:, 0], decoding_loss_only[:, 1], '-.', 'b')\n",
    "plt.xlabel('Epoch')\n",
    "ax1.set_ylabel('Norm of change in CNN weights')\n",
    "ax2.set_ylabel('Test loss')\n",
    "plt.title('Norm of change in CNN weights over time')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.behavior_decoder)\n",
    "# plot the cnn kernel\n",
    "input_cnn = model.behavior_decoder.conv_choice[0].weight.detach().numpy()\n",
    "# make two subplots\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(input_cnn[0, 0, :], label='input_c1', color='red')\n",
    "axs[0].plot(input_cnn[1, 0, :], label='input_c2', color='blue')\n",
    "# axs[0].plot(input_cnn[2, 0, :], label='input_c2', color='blue')\n",
    "# axs[0].plot(input_cnn[3, 0, :], label='input_c2', color='blue')\n",
    "\n",
    "middle_cnn = model.behavior_decoder.conv_choice[3].weight.detach().numpy()\n",
    "axs[1].plot(middle_cnn[0, 0, :], label='layer1_c1', color='red')\n",
    "axs[1].plot(middle_cnn[1, 0, :], label='layer2_c2', color='blue')\n",
    "# axs[1].plot(middle_cnn[2, 0, :], label='layer2_c2', color='blue')\n",
    "# axs[1].plot(middle_cnn[3, 0, :], label='layer2_c2', color='blue')\n",
    "# last_cnn = model.behavior_decoder.conv_choice[6].weight.detach().numpy()\n",
    "# axs[2].plot(last_cnn[0, 0, :], label='layer3_c1', color='green')\n",
    "# axs[2].plot(last_cnn[1, 0, :], label='layer3_c2', color='yellow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot energy of spikes\n",
    "# make 4 subplots\n",
    "# for i in range(4):\n",
    "#     idx = np.random.randint(len(spikes))\n",
    "#     spikes_emergy = np.linalg.norm(spikes_np[idx], axis=1, ord=1)\n",
    "#     ax = plt.subplot(2, 2, i+1)\n",
    "#     if i == 0:\n",
    "#         ax.set_title('Energy of spikes for random trials')\n",
    "#     if i == 2:\n",
    "#         ax.set_ylabel('L1 norm of spikes for trial {idx}')\n",
    "#         ax.set_xlabel('Time bin')\n",
    "#     ax.plot(spikes_emergy)\n",
    "spikes_energy = np.linalg.norm(spikes_np, axis=2, ord=1)\n",
    "# plot mean and standard deviation of energy of spikes\n",
    "mean_energy = np.mean(spikes_energy, axis=0)\n",
    "std_energy = np.std(spikes_energy, axis=0)\n",
    "plt.plot(mean_energy)\n",
    "plt.fill_between(np.arange(mean_energy.shape[0]), mean_energy-std_energy, mean_energy+std_energy, alpha=0.3)\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('L1 norm of spikes')\n",
    "plt.title('Mean and standard deviation of energy of spikes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# import SVM\n",
    "from sklearn.svm import SVC\n",
    "# import LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# use a SVM/LR model to decode the stimulus and choice\n",
    "# reshape the data\n",
    "# y_recon_train, mu_train, A_train, z_train, x_train, _ = model.forward(spikes_train, n_samples=1)\n",
    "for z_idx in range(3):\n",
    "    print('z_idx: {}'.format(z_idx))\n",
    "    # data_train = (x_train * z_train)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_test = (x_test * z_test)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_train = (mu_train)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_test = (mu_test)[:, :, z_idx].reshape(-1, 25)\n",
    "    data_train = (x_train * z_train).reshape(-1, 75)\n",
    "    data_test = (x_test * z_test).reshape(-1, 75)\n",
    "    for stim_choice_idx in range(2):\n",
    "        print('stim_choice_idx: {}'.format(stim_choice_idx))\n",
    "        y_train = np.tile(behaviour_data_train[:, stim_choice_idx].numpy(), 1)\n",
    "        y_test = np.tile(behaviour_data_test[:, stim_choice_idx].numpy(), 1)\n",
    "        # print(data_train.shape, y_train.shape)\n",
    "        # train the model\n",
    "        log_reg = SVC()\n",
    "        # log_reg = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "        log_reg.fit(data_train, y_train)\n",
    "        # test accuracy\n",
    "        accuracy_train = accuracy_score(y_train, log_reg.predict(data_train))\n",
    "        accuracy_test = accuracy_score(y_test, log_reg.predict(data_test))\n",
    "        print('{:.4f}/{:.4f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
