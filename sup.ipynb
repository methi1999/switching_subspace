{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from model import Model\n",
    "import utils\n",
    "from early_stopping import EarlyStopping\n",
    "from priors import moving_average\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "# set seeds\n",
    "utils.set_seeds(config['seed'])\n",
    "# utils.set_seeds(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_data, spikes, trial_ids = utils.load_dataset(config)\n",
    "# consider data from only t = -1\n",
    "# time_from = int(1/bin_len)\n",
    "# behaviour_data, spikes = [x[time_from:, :] for x in behaviour_data], [x[time_from:, :] for x in spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx, choice_idx, amp_idx = 9, 3, 24\n",
    "stim = [x[0, stim_idx] for x in behaviour_data]\n",
    "choice = [x[0, choice_idx] for x in behaviour_data]\n",
    "amp = torch.tensor([x[:, amp_idx] for x in behaviour_data], dtype=torch.float32)\n",
    "# normalize amp by max value\n",
    "amp = amp / amp.max()\n",
    "num_contacts = [np.sum(x[:, 15:19], axis=1) for x in behaviour_data]\n",
    "# concat them\n",
    "behaviour_data = np.stack((stim, choice), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "behaviour_data = torch.tensor(behaviour_data, dtype=torch.long)\n",
    "# behaviour_data = torch.tensor(behaviour_data, dtype=torch.float32)\n",
    "spikes = torch.tensor(spikes, dtype=torch.float32)\n",
    "num_trials, time_bins, emissions_dim = np.array(spikes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader with random sampling for training and testing\n",
    "# split data into training and testing\n",
    "# behaviour_data_train, behaviour_data_test, spikes_train, spikes_test = train_test_split(behaviour_data, spikes, test_size=0.3, random_state=42)\n",
    "behaviour_data_train, behaviour_data_test, spikes_train, spikes_test, amp_train, amp_test = train_test_split(behaviour_data, spikes, amp, test_size=0.2, random_state=7)\n",
    "# create dataloaders\n",
    "train_dataset = TensorDataset(behaviour_data_train, spikes_train, amp_train)\n",
    "test_dataset = TensorDataset(behaviour_data_test, spikes_test, amp_test)\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution of Stimulus: 0.46875, Choice: 0.359375\n",
      "Test distribution of Stimulus: 0.5454545454545454, Choice: 0.48484848484848486\n"
     ]
    }
   ],
   "source": [
    "# distribution of choice and stimulus in test\n",
    "print(\"Train distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_train[:, 0].numpy()), np.mean(behaviour_data_train[:, 1].numpy())))\n",
    "print(\"Test distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_test[:, 0].numpy()), np.mean(behaviour_data_test[:, 1].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean firing rate of neurons in tran spikes\n",
    "neuron_bias = torch.mean(spikes_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if mps is available\n",
    "# device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')\n",
    "# print(device)\n",
    "# model = model.to(device)\n",
    "# spikes = spikes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (behavior_batch, spikes_batch, amp_batch) in enumerate(test_loader):\n",
    "            vae_pred, behavior_pred, amp_pred = model(spikes_batch, n_samples=20, use_mean_for_decoding=True)\n",
    "            # calculate loss\n",
    "            loss, loss_l = model.loss(np.inf, spikes_batch, behavior_batch, amp_batch, vae_pred, behavior_pred, amp_pred)\n",
    "            # l.append(loss_l[1])\n",
    "            test_loss += np.array(loss_l)            \n",
    "            # print(np.mean(l), np.std(l))\n",
    "    # divide loss by total number of samples in dataloader    \n",
    "    return test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log det: tensor(-74.5478) Inverse max:  tensor(63.9476) Covariance max:  tensor(0.5100)\n",
      "Number of trainable parameters in RNN: 2400\n",
      "Number of trainable parameters in Posterior Mean: 190\n",
      "Number of trainable parameters in Block Diagonal Z: 163\n",
      "Number of trainable parameters in Cov X: 217\n",
      "Number of trainable parameters in VAE: 3217\n",
      "Using stimulus decoder\n",
      "Using choice decoder\n",
      "Scheduler not implemented for decoder\n",
      "Number of trainable parameters in behavior decoder: 132\n",
      "vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_10_[True, True, False]_3_entropy_None_seed_7cnn_0_1_None\n"
     ]
    }
   ],
   "source": [
    "config = utils.read_config()\n",
    "# create model and optimizer\n",
    "model = Model(config, input_dim=emissions_dim)\n",
    "# model = Model(config, input_dim=emissions_dim, neuron_bias=neuron_bias)\n",
    "# model = torch.compile(model)\n",
    "early_stop = EarlyStopping(patience=config['early_stop']['patience'], delta=config['early_stop']['delta'], trace_func=print)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=1, verbose=True, patience=5, factor=0.5)\n",
    "# print named parameters of model\n",
    "# print(\"Model's state_dict:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "print(model.arch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/2000], Train Loss: [984.53137207  20.76473618], Test Loss: [989.55944824  20.79663467], Best Loss: 1010.3560829162598\n",
      "Saved best\n",
      "Epoch [40/2000], Train Loss: [956.04943848  20.72667122], Test Loss: [965.03918457  20.79874229], Best Loss: 985.837926864624\n",
      "Saved best\n",
      "Epoch [60/2000], Train Loss: [944.80841064  20.71477509], Test Loss: [953.96533203  20.79792213], Best Loss: 974.7632541656494\n",
      "Saved best\n",
      "Epoch [80/2000], Train Loss: [933.64581299  20.75391006], Test Loss: [941.94555664  20.8018055 ], Best Loss: 962.7473621368408\n",
      "Saved best\n",
      "Epoch [100/2000], Train Loss: [925.98358154  20.61328506], Test Loss: [934.53643799  20.79546738], Best Loss: 955.3319053649902\n",
      "Saved best\n",
      "Epoch [120/2000], Train Loss: [919.29376221  19.86849594], Test Loss: [927.4541626   20.77772141], Best Loss: 948.2318840026855\n",
      "Saved best\n",
      "Epoch [140/2000], Train Loss: [912.62780762  18.85104752], Test Loss: [920.59735107  20.78932571], Best Loss: 941.3866767883301\n",
      "Saved best\n",
      "Epoch [160/2000], Train Loss: [904.65869141  17.45490074], Test Loss: [912.05987549  20.71642303], Best Loss: 932.7762985229492\n",
      "Saved best\n",
      "Epoch [180/2000], Train Loss: [898.31652832  14.08116531], Test Loss: [905.9329834  20.6315155], Best Loss: 926.5644989013672\n",
      "Saved best\n",
      "Epoch [200/2000], Train Loss: [894.39373779  10.16298866], Test Loss: [902.09362793  20.65256882], Best Loss: 922.7461967468262\n",
      "Saved best\n",
      "Epoch [220/2000], Train Loss: [890.71032715   8.39951229], Test Loss: [898.34661865  20.59681511], Best Loss: 918.9434337615967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m         meds\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmax(only_test_loss[i\u001b[38;5;241m-\u001b[39mhalf_window:i\u001b[38;5;241m+\u001b[39mhalf_window]))\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(meds), train_losses, test_losses\n\u001b[0;32m---> 77\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# min_test_loss, train_losses, test_losses = train(model, test_loader)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [36], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, early_stop)\u001b[0m\n\u001b[1;32m     25\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(loss_l)            \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# backward pass            \u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print gradient of any weight\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if epoch > 10:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     print(model.behavior_decoder.conv_choice[1].weight.grad)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m optim_size:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "def train(model: Model, train_loader, val_loader, early_stop):    \n",
    "    test_every = config['test_every']    \n",
    "    train_decoder_after = config['decoder']['train_decoder_after']    \n",
    "    num_samples_train = config['num_samples_train']\n",
    "    optim_size = config['optim_size']\n",
    "    save_model = True    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # forward pass\n",
    "        # print(model.behavior_decoder.scheduler.get_last_lr())\n",
    "        # model.vae.scheduler.get_last_lr()\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        model.optim_zero_grad()\n",
    "        optim_counter = 0\n",
    "        for i, (behavior_batch, spikes_batch, amp_batch) in enumerate(train_loader):            \n",
    "            # behavior_batch = behavior_batch.long()\n",
    "            vae_pred, behavior_pred, amp_pred = model(spikes_batch, n_samples=num_samples_train, use_mean_for_decoding=False)            \n",
    "            optim_counter += len(behavior_batch)\n",
    "            # calculate loss\n",
    "            loss, loss_l = model.loss(epoch, spikes_batch, behavior_batch, amp_batch, vae_pred, behavior_pred, amp_pred)\n",
    "            epoch_loss += np.array(loss_l)            \n",
    "            # backward pass            \n",
    "            loss.backward()\n",
    "            \n",
    "            # print gradient of any weight\n",
    "            # if epoch > 10:\n",
    "            #     print(model.behavior_decoder.conv_choice[1].weight.grad)\n",
    "            if optim_counter >= optim_size:\n",
    "                model.optim_step(train_decoder = epoch >= train_decoder_after)\n",
    "                model.optim_zero_grad()\n",
    "                print(\"Stepping inside\")\n",
    "                optim_counter = 0\n",
    "        # do it for the rest        \n",
    "        model.optim_step(train_decoder = epoch >= train_decoder_after)\n",
    "        model.optim_zero_grad()\n",
    "        \n",
    "        # if epoch % 100 == 0:\n",
    "        #     # print lr of decoder\n",
    "        #     print(model.behavior_decoder.scheduler.get_last_lr())\n",
    "        train_losses.append((epoch, epoch_loss/len(train_loader)))\n",
    "        model.scheduler_step(step_decoder = epoch >= train_decoder_after)\n",
    "        # test loss\n",
    "        if (epoch+1) % test_every == 0:\n",
    "            test_loss = test(model, val_loader)\n",
    "            sum_test_loss = np.sum(test_loss)\n",
    "            # scheduler.step(sum_test_loss)\n",
    "            test_losses.append((epoch, test_loss))\n",
    "            early_stop(sum_test_loss, model, save_model=save_model, save_prefix='best')\n",
    "            model.save_model(save_prefix=str(epoch))\n",
    "            print('Epoch [{}/{}], Train Loss: {}, Test Loss: {}, Best Loss: {}'.format(epoch+1, config['epochs'], train_losses[-1][1], test_losses[-1][1], early_stop.best_score))\n",
    "            if early_stop.slow_down:\n",
    "                test_every = config['early_stop']['test_every_new']\n",
    "            else:\n",
    "                test_every = config['test_every']\n",
    "            if early_stop.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            \n",
    "    \n",
    "    only_test_loss = [np.sum(x[1]) for x in test_losses]\n",
    "    \n",
    "    # compute min test loss and return it    \n",
    "    # return np.min(only_test_loss), train_losses, test_losses\n",
    "    \n",
    "    # compute median of test loss in a window of 5\n",
    "    meds = []\n",
    "    half_window = 10\n",
    "    only_test_loss = [0]*(half_window) + only_test_loss + [0]*(half_window)\n",
    "    for i in range(half_window, len(only_test_loss)-half_window):\n",
    "        meds.append(np.max(only_test_loss[i-half_window:i+half_window]))\n",
    "    return np.min(meds), train_losses, test_losses\n",
    "\n",
    "_ = train(model, train_loader, test_loader, early_stop)\n",
    "# train model\n",
    "# min_test_loss, train_losses, test_losses = train(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_og, test_losses_og = train_losses[:], test_losses[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.prior_modules[0].plot_gaussian()\n",
    "# model.prior_modules[0].log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_loss_curve(model, config, train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort list by test loss\n",
    "sorted_loss = sorted(test_losses, key=lambda x: x[1][1], reverse=True) \n",
    "# extract first element after epoch 600\n",
    "sorted_loss = [(x[0], x[1][1]/100) for x in sorted_loss if x[0] > 100]\n",
    "print(sorted_loss[:2], sorted_loss[-10:])\n",
    "# print(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_model('best')\n",
    "# model.load_model(save_prefix='best', base_path='/Users/mithileshvaidya/Code/VAE/revised/results/dandi_sub-221CR_ses-20190515T160400/100_ms/3monotonicitybest_vae_gp_[1, 1, 1]_diagonal_gru_8_2_True_noise_0.01_rbfscale_0.5_smoothing_3_monotonic_1_1_20_[True, True, False]_3_entropy_None')\n",
    "# load model from epoch x\n",
    "# model.load_model('219')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_maps = model.vae.linear_maps\n",
    "c1, c2 = lin_maps[0].weight.detach().numpy(), lin_maps[1].weight.detach().numpy()\n",
    "print(c1, c2)\n",
    "# print(c1.T.dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2)))\n",
    "# with open(utils.model_store_path(config, model.arch_name) + '/subspaces_filtered.pkl', 'wb') as f:\n",
    "#     pickle.dump(lin_maps, f)\n",
    "# find cosine similarity of all pairs\n",
    "# print(c1.T.dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2)), c1.T.dot(c3)/(np.linalg.norm(c1)*np.linalg.norm(c3)), c2.T.dot(c3)/(np.linalg.norm(c2)*np.linalg.norm(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print cnn weights\n",
    "conv_weights = model.behavior_decoder.conv_stim[0].weight.detach().numpy()\n",
    "plt.imshow(conv_weights[:, 0, :])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bits per spike train: 0.2805020213127136, test: 0.2527989447116852, all: 0.2798413634300232\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'green', 'black', 'yellow', 'pink']\n",
    "# convert to numpy\n",
    "spikes_train_np = spikes_train.detach().numpy()\n",
    "spikes_test_np = spikes_test.detach().numpy()\n",
    "spikes_np = spikes.detach().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()        \n",
    "    # run on only test\n",
    "    vae_output, _, amp_out_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=True)  \n",
    "    y_recon_test, x_mu_test, z_mu_test, x_A_test, z_A_test, x_test, z_test, z_test_presoftmax, g_test = model.vae.extract_relevant(vae_output)\n",
    "    # run only on train\n",
    "    vae_output, _, amp_out_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=True)\n",
    "    y_recon_train, x_mu_train, z_mu_train, x_A_train, z_A_train, x_train, z_train, z_train_presoftmax, g_train = model.vae.extract_relevant(vae_output)\n",
    "    # run on both\n",
    "    vae_output, _, amp_out_all = model.forward(spikes, n_samples=1, use_mean_for_decoding=True)\n",
    "    y_recon_all, x_mu_all, z_mu_all, x_A_all, z_A_all, x_all, z_all, z_presoftmax_all, g_all = model.vae.extract_relevant(vae_output)\n",
    "\n",
    "# compute bits/spike\n",
    "bits_per_spike_train = utils.bits_per_spike(y_recon_train, spikes_train_np)\n",
    "bits_per_spike_test = utils.bits_per_spike(y_recon_test, spikes_test_np)\n",
    "bits_per_spike = utils.bits_per_spike(y_recon_all, spikes_np)\n",
    "# # show distribution of bits per spike\n",
    "# plt.hist(bits_per_spike_train, bins=50)\n",
    "# plt.xlabel('Bits/spike')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "# print('Bits per spike: {}'.format(bits_per_spike))\n",
    "print(\"Bits per spike train: {}, test: {}, all: {}\".format(np.sum(bits_per_spike_train), np.sum(bits_per_spike_test), np.sum(bits_per_spike)))\n",
    "\n",
    "to_write = (y_recon_train, x_mu_train, z_mu_train, x_A_train, z_A_train, x_train, z_train, z_train_presoftmax, g_train,\n",
    "            y_recon_test, x_mu_test, z_mu_test, x_A_test, z_A_test, x_test, z_test, z_test_presoftmax, g_test,\n",
    "            amp_out_train, amp_out_test)\n",
    "pth = os.path.join(utils.model_store_path(config, model.arch_name), 'res.pkl')\n",
    "with open(pth, 'wb') as f:\n",
    "    pickle.dump(to_write, f)\n",
    "# print(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov = np.mean(z_A_train, axis=0)[10, :, :]\n",
    "# print(cov)\n",
    "# plt.imshow(np.linalg.inv(cov))\n",
    "fig, ax = plt.subplots(3, 1, figsize=(3, 9))\n",
    "for i in range(3):\n",
    "    cov = np.mean(z_A_train, axis=0)[:, :, i]    \n",
    "    im = ax[i].imshow(cov)\n",
    "    ax[i].set_title(\"Covariance of z{}\".format(i))\n",
    "    plt.colorbar(im, ax=ax[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PSTH of reconstructed and original data\n",
    "averaged_recon, averaged_original = y_recon.mean(axis=0), spikes_np.mean(axis=0)\n",
    "# stimulus and choice important\n",
    "common = [12, 14, 4, 31]\n",
    "stim_neurons = [15, 11, 33, 30]\n",
    "choice_neurons = [16, 2, 6, 8]\n",
    "# plot each in a 5x7 grid\n",
    "fig, axs = plt.subplots(5, 7, figsize=(12, 9))\n",
    "# set title of figure\n",
    "fig.suptitle('yellow: choice, green: stimulus, pink: common')\n",
    "for i in range(5):\n",
    "    for j in range(7):\n",
    "        neuron_idx = i*7+j        \n",
    "        axs[i, j].plot(averaged_recon[:, neuron_idx], label='recon', color='red')\n",
    "        axs[i, j].plot(averaged_original[:, neuron_idx], label='original', color='blue')\n",
    "        # no ticks\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "        # set title of plot to neuron index\n",
    "        # print only 2 decimal places        \n",
    "        axs[i, j].set_title('{}: {:.4f}'.format(neuron_idx, bits_per_spike_all[neuron_idx]))\n",
    "        # set background color of plot to green if neuron in choice\n",
    "        if neuron_idx in choice_neurons:\n",
    "            axs[i, j].set_facecolor('yellow')\n",
    "        # set background color of plot to red if neuron in stimulus\n",
    "        if neuron_idx in stim_neurons:\n",
    "            axs[i, j].set_facecolor('green')\n",
    "        # set background color of plot to blue if neuron in common\n",
    "        if neuron_idx in common:\n",
    "            axs[i, j].set_facecolor('pink')\n",
    "axs[0, 0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x305cc55a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot trial averaged latent space\n",
    "# z, x = torch.nn.Softmax(dim=2)(mu[:, :, :model.vae.z_dim]).numpy(), mu[:, :, model.vae.z_dim:].numpy()\n",
    "z = z_all\n",
    "# z = z_mu_all\n",
    "# z = z_all_presoftmax\n",
    "# x = x_all\n",
    "x = x_mu_all\n",
    "z_std = np.std(z, axis=0)\n",
    "z_avg = np.mean(z, axis=0)\n",
    "# make x ticks of range 0.1 from -2 to 0.5\n",
    "bin_len = config['shape_dataset']['win_len']\n",
    "t = np.arange(-2, 0.5, bin_len)\n",
    "for i in range(z.shape[2]):\n",
    "    plt.plot(t, z_avg[:, i], label='z{}'.format(i), color=colors[i])    \n",
    "    plt.fill_between(t, z_avg[:, i]-z_std[:, i], z_avg[:, i]+z_std[:, i], alpha=0.3, color=colors[i])\n",
    "# plt.set_title('z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cont_latent(data, label, ax_id, linestyle):\n",
    "    num_latents = data.shape[1]\n",
    "    for i in range(num_latents):\n",
    "        axs[ax_id].plot(t, data[:, i], label='{}_x{}'.format(label, i),\n",
    "                        color=colors[i], linestyle=linestyle)    \n",
    "    \n",
    "# behave_data, x_data = behaviour_data_train, x_train\n",
    "# behave_data, x_data = behaviour_data_train, x_train*z_train\n",
    "behave_data, x_data = behaviour_data_test, x_test\n",
    "# behave_data, x_data = behaviour_data, x\n",
    "# group x for stimulus and choice\n",
    "stim, choice = behave_data[:, 0].numpy(), behave_data[:, 1].numpy()\n",
    "# group x for stimulus\n",
    "x_stim_left, x_stim_right = x_data[stim == 1].mean(axis=0), x_data[stim == 0].mean(axis=0)\n",
    "x_choice_left, x_choice_right = x_data[choice == 1].mean(axis=0), x_data[choice == 0].mean(axis=0)\n",
    "# plot x for stimulus and choice\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "plot_cont_latent(x_stim_left, 'stim left', 0, '-')\n",
    "plot_cont_latent(x_stim_right, 'stim right', 0, '-.')\n",
    "axs[0].set_title('x grouped by stimulus')\n",
    "axs[0].legend()\n",
    "\n",
    "plot_cont_latent(x_choice_left, 'choice left', 1, '-')\n",
    "plot_cont_latent(x_choice_right, 'choice right', 1, '-.')\n",
    "axs[1].set_title('x grouped by choice')\n",
    "axs[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x on 2d\n",
    "choice = behaviour_data[:, 1].numpy()\n",
    "# group x for stimulus\n",
    "x_choice_left, x_choice_right = x[choice == 1].mean(axis=0), x[choice == 0].mean(axis=0)\n",
    "z_choice_left, z_choice_right = z[choice == 1].mean(axis=0), z[choice == 0].mean(axis=0)\n",
    "# plot first 2 dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x_choice_left[:, 0], x_choice_left[:, 1], label='choice left', color='red')\n",
    "ax.plot(x_choice_right[:, 0], x_choice_right[:, 1], label='choice right', color='blue')\n",
    "# mark starting point\n",
    "ax.scatter(x_choice_left[0, 0], x_choice_left[0, 1], color='red')\n",
    "ax.scatter(x_choice_right[0, 0], x_choice_right[0, 1], color='blue')\n",
    "ax.legend()\n",
    "ax.set_title('x grouped by choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decoder\n",
    "nsamps = config['num_samples_train']\n",
    "with torch.no_grad():\n",
    "    model.eval()    \n",
    "    _, mu_train, A_train, z_train_all, x_train_all, _ = model.forward(spikes_train, n_samples=nsamps)\n",
    "    _, mu_test, A_test, z_test_all, x_test_all, _ = model.forward(spikes_test, n_samples=nsamps)\n",
    "\n",
    "z_train, x_train = z_train_all[:, :, 2:], x_train_all[:, :, 2:]\n",
    "z_test, x_test = z_test_all[:, :, 2:], x_test_all[:, :, 2:]\n",
    "# train the linear decoder for behavior\n",
    "# create linear decoder\n",
    "linear_decoder = decoder.CNNDecoderIndividual(config, [0, 1, 0])\n",
    "decoder_train_l, decoder_test_l = [], []\n",
    "for epoch in range(100):    \n",
    "    # forward pass        \n",
    "    linear_decoder.train()\n",
    "    behavior_pred = linear_decoder(x_train, z_train)\n",
    "    # print(behavior_pred)\n",
    "    # behavior_pred = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    # print(behavior_pred.shape, behaviour_data_train.shape)\n",
    "    loss = linear_decoder.loss(behavior_pred, behaviour_data_train, None)\n",
    "    # backward pass\n",
    "    linear_decoder.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    linear_decoder.optimizer.step()\n",
    "    epoch_loss = loss.item()    \n",
    "    decoder_train_l.append(epoch_loss)\n",
    "    # test loss\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        linear_decoder.eval()\n",
    "        test_pred = linear_decoder(x_test, z_test)\n",
    "        # behavior_pred = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "        test_loss = linear_decoder.loss(test_pred, behaviour_data_test, None).item()        \n",
    "        decoder_test_l.append(test_loss)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, num_epochs, decoder_train_l[-1], decoder_test_l[-1]))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    behavior_pred_train = linear_decoder(x_train, z_train).detach()\n",
    "    behavior_pred_test = linear_decoder(x_test, z_test).detach()\n",
    "    # behavior_pred_train = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    # behavior_pred_test = linear_decoder(mu_test[:, :, :2], mu_test[:, :, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_pred_train, agg_pred_test = [], []\n",
    "agg_y_train, agg_y_test = [], []\n",
    "# convert to numpy\n",
    "y_train = behaviour_data_train.numpy()\n",
    "y_test = behaviour_data_test.numpy()\n",
    "# accuracy of stimulus and choice\n",
    "acc_stim_train, acc_stim_test = [], []\n",
    "acc_choice_train, acc_choice_test = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    behavior_pred_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=True)[1]\n",
    "    behavior_pred_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=True)[1]\n",
    "    # behavior_pred_train = model.forward(spikes_train, n_samples=1, use_mean_for_decoding=False)[1]\n",
    "    # behavior_pred_test = model.forward(spikes_test, n_samples=1, use_mean_for_decoding=False)[1]\n",
    "    # convert to numpy\n",
    "    # pred_train = behavior_pred_train.numpy() > 0\n",
    "    # pred_test = behavior_pred_test.numpy() > 0        \n",
    "    pred_train_stim = torch.argmax(behavior_pred_train[:, :2], dim=1).numpy()\n",
    "    pred_test_stim = torch.argmax(behavior_pred_test[:, :2], dim=1).numpy()\n",
    "    pred_train_choice = torch.argmax(behavior_pred_train[:, 2:4], dim=1).numpy()\n",
    "    pred_test_choice = torch.argmax(behavior_pred_test[:, 2:4], dim=1).numpy()    \n",
    "    # compute accuracy        \n",
    "    accuracy_train_stim = accuracy_score(y_train[:, 0], pred_train_stim)\n",
    "    accuracy_test_stim = accuracy_score(y_test[:, 0], pred_test_stim)        \n",
    "    # do the same for choice\n",
    "    accuracy_train_choice = accuracy_score(y_train[:, 1], pred_train_choice)\n",
    "    accuracy_test_choice = accuracy_score(y_test[:, 1], pred_test_choice)    \n",
    "# print accuracy\n",
    "print(\"Accuracy of stimulus train: {}, test: {}\".format(accuracy_train_stim, accuracy_test_stim))\n",
    "print(\"Accuracy of choice train: {}, test: {}\".format(accuracy_train_choice, accuracy_test_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random trial\n",
    "stim, choice = behaviour_data[:, 0].numpy(), behaviour_data[:, 1].numpy()\n",
    "amp_pred_ = amp_out_all.numpy()\n",
    "# examine a random trial\n",
    "trial_idx = np.random.randint(len(z))\n",
    "# trial_idx = 87\n",
    "# plot_g = False\n",
    "plot_g = True\n",
    "# trial_idx = 1\n",
    "# plot z and x\n",
    "# z = g_train\n",
    "if plot_g:\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(5, 8))\n",
    "else:\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(5, 8))\n",
    "# plot z\n",
    "# apply softmax\n",
    "# z[trial_idx, :] = np.exp(z[trial_idx, :])/np.sum(np.exp(z[trial_idx, :]), axis=1)[:, None]\n",
    "bin_len = config['shape_dataset']['win_len']\n",
    "t = np.arange(-2, 0.5, bin_len)\n",
    "axs[0].plot(t, z[trial_idx, :, 0], label='z0', marker='o', color=colors[0])\n",
    "axs[0].plot(t, z[trial_idx, :, 1], label='z1', marker='o', color=colors[1])\n",
    "axs[0].plot(t, z[trial_idx, :, 2], label='z2', marker='o', color=colors[2])\n",
    "axs[0].set_title('z for a random trial:'+str(trial_idx))\n",
    "# axs[0].set_ylim(0, 1)\n",
    "axs[0].legend()\n",
    "axs[0].set_xticks([])\n",
    "# plot num contacts\n",
    "axs[1].plot(t, num_contacts[trial_idx], marker='o', label='num contacts')\n",
    "axs[1].set_title('num contacts and amplitude of whisk')\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_ylabel('Num contacts')\n",
    "axs[1].legend(loc='upper left')\n",
    "# plot on right y axis\n",
    "ax2 = axs[1].twinx()\n",
    "ax2.plot(t, amp[trial_idx], marker='o', label='amplitude y', color='red')\n",
    "ax2.plot(t, amp_pred_[trial_idx], marker='o', label='amplitude pred', color='green')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "\n",
    "# # plot time bin distribution\n",
    "# tbd = misc_all[2]\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 0], label='z0', marker='o')\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 1], label='z1', marker='o')\n",
    "# axs[2].plot(t, tbd[trial_idx, :, 2], label='z2', marker='o')\n",
    "# axs[2].set_title('Softmax output of z before computing peak')\n",
    "# plot x\n",
    "axs[2].plot(t, x[trial_idx, :, 0], label='x0', marker='o', color=colors[0])\n",
    "axs[2].plot(t, x[trial_idx, :, 1], label='x1', marker='o', color=colors[1])\n",
    "axs[2].plot(t, x[trial_idx, :, 2], label='x2', marker='o', color=colors[2])\n",
    "axs[2].plot(t, x[trial_idx, :, 3], label='x3', marker='o', color=colors[3])\n",
    "axs[2].plot(t, x[trial_idx, :, 4], label='x4', marker='o', color=colors[4])\n",
    "axs[2].plot(t, x[trial_idx, :, 5], label='x5', marker='o', color=colors[5])\n",
    "axs[2].set_title('x, stimulus: {}, choice: {}'.format(stim[trial_idx].astype(int), choice[trial_idx].astype(int)))\n",
    "\n",
    "if plot_g:\n",
    "    # plot g\n",
    "    def dt(x):\n",
    "        # pad with zeros on both side. x is of shape (t,)\n",
    "        x = np.concatenate((np.zeros((1,)), x, np.zeros((1,))), axis=0)\n",
    "        # compute difference\n",
    "        centred = (x[2:] - x[:-2])/2\n",
    "        # forward\n",
    "        forward = x[2:] - x[1:-1]\n",
    "        # backward\n",
    "        backward = x[1:-1] - x[:-2]        \n",
    "        return forward\n",
    "    g = g_all\n",
    "    axs[3].plot(t, g[trial_idx, :, 0], label='g0', marker='o')\n",
    "    axs[3].plot(t, g[trial_idx, :, 1], label='g1', marker='o')\n",
    "    # axs[3].plot(t, g[trial_idx, :, 2], label='g2', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 0]), label='dg0', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 1]), label='dg1', marker='o')\n",
    "    # axs[3].plot(t, dt(g[trial_idx, :, 2]), label='dg2', marker='o')\n",
    "    axs[3].set_title('g, stimulus: {}, choice: {}'.format(stim[trial_idx].astype(int), choice[trial_idx].astype(int)))\n",
    "    # axs[3].set_ylim(-2, 2)\n",
    "    axs[3].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sklearn logistic regression model for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def reshape(x, y):\n",
    "    trials, time, dim = x.shape\n",
    "    # x = x[:, -5:-4, :]\n",
    "    return x.reshape(trials, -1), y\n",
    "\n",
    "stim_choice = 0\n",
    "\n",
    "x_train_baseline, y_train_baseline = reshape(spikes_train, behaviour_data_train)\n",
    "x_test_baseline, y_test_baseline = reshape(spikes_test, behaviour_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "log_reg = LogisticRegression(penalty='l1', C=1, solver='liblinear', verbose=1)\n",
    "# log_reg = SVC()\n",
    "log_reg.fit(x_train_baseline, y_train_baseline[:, stim_choice])\n",
    "# test accuracy\n",
    "accuracy_train = accuracy_score(y_train_baseline[:, stim_choice], log_reg.predict(x_train_baseline))\n",
    "accuracy_test = accuracy_score(y_test_baseline[:, stim_choice], log_reg.predict(x_test_baseline))\n",
    "print('Logistic Regression Accuracy - train: {:.4f}, test: {:.4f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Define logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(875, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = LogisticRegressionModel()\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x_train_baseline)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, y_train_baseline[:, stim_choice:stim_choice+1])\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    with torch.no_grad():    \n",
    "        predicted_prob = model(x_test_baseline)\n",
    "        test_losses.append(criterion(predicted_prob, y_test_baseline[:, stim_choice:stim_choice+1]).item())\n",
    "        predicted_class = (predicted_prob >= 0.5).float()\n",
    "        accuracy = (predicted_class == y_test_baseline[:, stim_choice:stim_choice+1]).float().mean()\n",
    "print(f'Accuracy: {accuracy.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg coeff\n",
    "# plot coefficients in a 2d grid\n",
    "# c = log_reg.coef_.reshape(-1, 25)\n",
    "# plt.imshow(c)\n",
    "\n",
    "# plot nn coefficients\n",
    "c = model.linear.weight.detach().numpy().reshape(-1, 25)\n",
    "plt.imshow(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and standard deviation of decoding loss over trials\n",
    "model.eval()\n",
    "# print(\"Total models to study:\", len(test_losses[:10] + test_losses[10::20]))\n",
    "print(\"Total models to study:\", len(test_losses))\n",
    "test_losses_aggregated = []\n",
    "z_agg, x_agg = [], []\n",
    "cov_norm = []\n",
    "cnn_weights = []\n",
    "decoding_runs = 50\n",
    "# for epoch, _ in test_losses[:10] + test_losses[10::20]:\n",
    "for epoch, _ in test_losses:\n",
    "    # print(epoch)\n",
    "    # if epoch != 331:\n",
    "    #     continue\n",
    "    model.load_model(str(epoch))\n",
    "    cur_epoch_loss = []\n",
    "    cur_epoch_z, cur_epoch_x = [], []\n",
    "    with torch.no_grad():\n",
    "        cov_norm_current = []\n",
    "        for _ in range(decoding_runs):\n",
    "            test_loss = []\n",
    "            cur_run_z, cur_run_x = [], []\n",
    "            for _, (behavior_batch, spikes_batch) in enumerate(test_loader):\n",
    "                y_recon, mu, A, z, x, behavior_batch_pred = model(spikes_batch, n_samples=1, use_mean_for_decoding=False)\n",
    "                behavior_loss = model.behavior_decoder.loss(behavior_batch_pred, behavior_batch, z, reduction='none')                \n",
    "                test_loss.append(behavior_loss)\n",
    "                cur_run_z.append(z[:, :, 0])\n",
    "                cur_run_x.append(x[:, :, 0])\n",
    "                cov_norm_current.append(np.linalg.norm(A.numpy()))\n",
    "            # stack horizontally and take mean across samples\n",
    "            test_loss = torch.mean(torch.cat(test_loss, dim=0), dim=0).item()\n",
    "            cur_epoch_loss.append(test_loss)\n",
    "            # stack z and x\n",
    "            z_stacked, x_stacked = torch.cat(cur_run_z, dim=0), torch.cat(cur_run_x, dim=0)            \n",
    "            cur_epoch_z.append(z_stacked)\n",
    "            cur_epoch_x.append(x_stacked)\n",
    "        \n",
    "        test_losses_aggregated.append((epoch, np.mean(cur_epoch_loss), np.std(cur_epoch_loss)))\n",
    "        # compute std for z and x\n",
    "        z_std, x_std = torch.std(torch.stack(cur_epoch_z), dim=0), torch.std(torch.stack(cur_epoch_x), dim=0)        \n",
    "        \n",
    "        z_agg.append((epoch, z_std.mean().item()))\n",
    "        x_agg.append((epoch, x_std.mean().item()))\n",
    "        # cov norm\n",
    "        cov_norm.append((epoch, np.mean(cov_norm_current)))\n",
    "        # cnn weights\n",
    "        cnn_weights.append((epoch, deepcopy(model.behavior_decoder.conv_stim), deepcopy(model.behavior_decoder.conv_choice)))        \n",
    "# # plot histogram\n",
    "# plt.hist(test_loss.numpy(), range=(0, 7), bins=50, density=True)\n",
    "# plt.xlabel('Cross entropy loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Test decoding loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean and std of test loss\n",
    "test_losses_plot = np.array(test_losses_aggregated)\n",
    "# plt.errorbar(test_losses_plot[:, 0], test_losses_plot[:, 1], yerr=test_losses_plot[:, 2])\n",
    "# print(test_losses_plot)\n",
    "plt.plot(test_losses_plot[:, 0], test_losses_plot[:, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross entropy loss')\n",
    "plt.title('Test decoding loss mean and std over 200 runs at various epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x and z\n",
    "print(z_agg)\n",
    "z_agg_plot = np.array(z_agg)\n",
    "x_agg_plot = np.array(x_agg)\n",
    "plt.plot(z_agg_plot[:, 0], z_agg_plot[:, 1], label='z')\n",
    "plt.plot(x_agg_plot[:, 0], x_agg_plot[:, 1], label='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Standard deviation')\n",
    "plt.title('Standard deviation of z and x over 200 runs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot norm of covariance\n",
    "cov_norm_plot = np.array(cov_norm)\n",
    "plt.plot(cov_norm_plot[:, 0], cov_norm_plot[:, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Norm of covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine particular examples\n",
    "# get mean and standard deviation of decoding loss over trials\n",
    "model.eval()\n",
    "print(\"Total models to study:\", len(test_losses))\n",
    "test_losses_aggregated = []\n",
    "decoding_runs = 100\n",
    "for epoch, _ in test_losses[:10] + test_losses[10::20]:\n",
    "    # print(epoch)\n",
    "    model.load_model(str(epoch))\n",
    "    cur_epoch_loss = []    \n",
    "    with torch.no_grad():        \n",
    "        for _ in range(decoding_runs):\n",
    "            test_loss = []\n",
    "            cur_run_z, cur_run_x = [], []\n",
    "            for _, (behavior_batch, spikes_batch) in enumerate(test_loader):\n",
    "                y_recon, (mu, A), (z, x), behavior_batch_pred = model(spikes_batch)\n",
    "                behavior_loss = model.behavior_decoder.loss(behavior_batch_pred, behavior_batch, z, reduction='none')                \n",
    "                test_loss.append(behavior_loss)                \n",
    "            # stack horizontally and take mean across samples\n",
    "            test_loss = torch.cat(test_loss, dim=0)\n",
    "            cur_epoch_loss.append(test_loss)\n",
    "        # stack the losses across decoding runs\n",
    "        cur_epoch_loss = torch.stack(cur_epoch_loss, dim=0)\n",
    "        # compute mean and std of epoch loss across decoding runs\n",
    "        m, s = torch.mean(cur_epoch_loss, dim=0).numpy(), torch.std(cur_epoch_loss, dim=0).numpy()        \n",
    "        test_losses_aggregated.append((epoch, m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(15):\n",
    "    epochs = [x[0] for x in test_losses_aggregated]\n",
    "    losses = [x[2][idx] for x in test_losses_aggregated]\n",
    "    plt.plot(epochs, losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross entropy loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot norm of change in CNN weights over time\n",
    "cnn_idx = 2\n",
    "base_cnn = cnn_weights[0][cnn_idx]\n",
    "layers_to_study = [(x, base_cnn[x].__module__.split('.')[-1]) for x in range(len(base_cnn)) if isinstance(base_cnn[x], torch.nn.Conv1d) or isinstance(base_cnn[x], torch.nn.BatchNorm1d)]\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "for layer_idx, name in layers_to_study:    \n",
    "    change_in_norms = []\n",
    "    for i, (epoch, _, cur_cnn) in enumerate(cnn_weights):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        cur_weight = cur_cnn[layer_idx].weight.detach().numpy()\n",
    "        prev_epoch_weights = cnn_weights[i-1][cnn_idx][layer_idx].weight.detach().numpy()        \n",
    "        change_in_norm = np.linalg.norm(cur_weight - prev_epoch_weights)        \n",
    "        # normalize by total number of weights        \n",
    "        change_in_norm /= cur_weight.size\n",
    "        change_in_norms.append((epoch, change_in_norm))\n",
    "    change_in_norms = np.array(change_in_norms)    \n",
    "    ax1.plot(change_in_norms[:, 0], change_in_norms[:, 1], label=name)\n",
    "\n",
    "# plot test_losses_og \n",
    "decoding_loss_only = np.array([(x[0], x[1][1]) for x in test_losses_og])\n",
    "ax2.plot(decoding_loss_only[:, 0], decoding_loss_only[:, 1], '-.', 'b')\n",
    "plt.xlabel('Epoch')\n",
    "ax1.set_ylabel('Norm of change in CNN weights')\n",
    "ax2.set_ylabel('Test loss')\n",
    "plt.title('Norm of change in CNN weights over time')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.behavior_decoder)\n",
    "# plot the cnn kernel\n",
    "input_cnn = model.behavior_decoder.conv_choice[0].weight.detach().numpy()\n",
    "# make two subplots\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(input_cnn[0, 0, :], label='input_c1', color='red')\n",
    "axs[0].plot(input_cnn[1, 0, :], label='input_c2', color='blue')\n",
    "# axs[0].plot(input_cnn[2, 0, :], label='input_c2', color='blue')\n",
    "# axs[0].plot(input_cnn[3, 0, :], label='input_c2', color='blue')\n",
    "\n",
    "middle_cnn = model.behavior_decoder.conv_choice[3].weight.detach().numpy()\n",
    "axs[1].plot(middle_cnn[0, 0, :], label='layer1_c1', color='red')\n",
    "axs[1].plot(middle_cnn[1, 0, :], label='layer2_c2', color='blue')\n",
    "# axs[1].plot(middle_cnn[2, 0, :], label='layer2_c2', color='blue')\n",
    "# axs[1].plot(middle_cnn[3, 0, :], label='layer2_c2', color='blue')\n",
    "# last_cnn = model.behavior_decoder.conv_choice[6].weight.detach().numpy()\n",
    "# axs[2].plot(last_cnn[0, 0, :], label='layer3_c1', color='green')\n",
    "# axs[2].plot(last_cnn[1, 0, :], label='layer3_c2', color='yellow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot energy of spikes\n",
    "# make 4 subplots\n",
    "# for i in range(4):\n",
    "#     idx = np.random.randint(len(spikes))\n",
    "#     spikes_emergy = np.linalg.norm(spikes_np[idx], axis=1, ord=1)\n",
    "#     ax = plt.subplot(2, 2, i+1)\n",
    "#     if i == 0:\n",
    "#         ax.set_title('Energy of spikes for random trials')\n",
    "#     if i == 2:\n",
    "#         ax.set_ylabel('L1 norm of spikes for trial {idx}')\n",
    "#         ax.set_xlabel('Time bin')\n",
    "#     ax.plot(spikes_emergy)\n",
    "spikes_energy = np.linalg.norm(spikes_np, axis=2, ord=1)\n",
    "# plot mean and standard deviation of energy of spikes\n",
    "mean_energy = np.mean(spikes_energy, axis=0)\n",
    "std_energy = np.std(spikes_energy, axis=0)\n",
    "plt.plot(mean_energy)\n",
    "plt.fill_between(np.arange(mean_energy.shape[0]), mean_energy-std_energy, mean_energy+std_energy, alpha=0.3)\n",
    "plt.xlabel('Time bin')\n",
    "plt.ylabel('L1 norm of spikes')\n",
    "plt.title('Mean and standard deviation of energy of spikes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# import SVM\n",
    "from sklearn.svm import SVC\n",
    "# import LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# use a SVM/LR model to decode the stimulus and choice\n",
    "# reshape the data\n",
    "# y_recon_train, mu_train, A_train, z_train, x_train, _ = model.forward(spikes_train, n_samples=1)\n",
    "for z_idx in range(3):\n",
    "    print('z_idx: {}'.format(z_idx))\n",
    "    # data_train = (x_train * z_train)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_test = (x_test * z_test)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_train = (mu_train)[:, :, z_idx].reshape(-1, 25)\n",
    "    # data_test = (mu_test)[:, :, z_idx].reshape(-1, 25)\n",
    "    data_train = (x_train * z_train).reshape(-1, 75)\n",
    "    data_test = (x_test * z_test).reshape(-1, 75)\n",
    "    for stim_choice_idx in range(2):\n",
    "        print('stim_choice_idx: {}'.format(stim_choice_idx))\n",
    "        y_train = np.tile(behaviour_data_train[:, stim_choice_idx].numpy(), 1)\n",
    "        y_test = np.tile(behaviour_data_test[:, stim_choice_idx].numpy(), 1)\n",
    "        # print(data_train.shape, y_train.shape)\n",
    "        # train the model\n",
    "        log_reg = SVC()\n",
    "        # log_reg = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "        log_reg.fit(data_train, y_train)\n",
    "        # test accuracy\n",
    "        accuracy_train = accuracy_score(y_train, log_reg.predict(data_train))\n",
    "        accuracy_test = accuracy_score(y_test, log_reg.predict(data_test))\n",
    "        print('{:.4f}/{:.4f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
