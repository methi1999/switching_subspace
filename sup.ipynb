{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from decoder import LinearAccDecoder\n",
    "import utils\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "# set seeds\n",
    "utils.set_seeds(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_data, spikes = utils.load_dataset(config)\n",
    "# consider data from only t = -1\n",
    "# time_from = int(1/bin_len)\n",
    "# behaviour_data, spikes = [x[time_from:, :] for x in behaviour_data], [x[time_from:, :] for x in spikes]\n",
    "num_trials, time_bins, emissions_dim = np.array(spikes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx, choice_idx = 6, 3\n",
    "stim = [x[0, stim_idx] for x in behaviour_data]\n",
    "choice = [x[0, choice_idx] for x in behaviour_data]\n",
    "num_contacts = [np.sum(x[:, -9:-5], axis=1) for x in behaviour_data]\n",
    "# concat them\n",
    "behaviour_data = np.stack((stim, choice), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "behaviour_data = torch.tensor(behaviour_data, dtype=torch.float32)\n",
    "spikes = torch.tensor(spikes, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader with random sampling for training and testing\n",
    "# split data into training and testing\n",
    "behaviour_data_train, behaviour_data_test, spikes_train, spikes_test = train_test_split(behaviour_data, spikes, test_size=0.3, random_state=42)\n",
    "\n",
    "# create dataloaders\n",
    "train_dataset = TensorDataset(behaviour_data_train, spikes_train)\n",
    "test_dataset = TensorDataset(behaviour_data_test, spikes_test)\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of choice and stimulus in test\n",
    "print(\"Train distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_train[:, 0].numpy()), np.mean(behaviour_data_train[:, 1].numpy())))\n",
    "print(\"Test distribution of Stimulus: {}, Choice: {}\".format(np.mean(behaviour_data_test[:, 0].numpy()), np.mean(behaviour_data_test[:, 1].numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean firing rate of neurons in tran spikes\n",
    "neuron_bias = torch.mean(spikes_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.read_config()\n",
    "# training loop\n",
    "num_epochs, learning_rate = config['epochs'], config['lr']\n",
    "# create model and optimizer\n",
    "model = Model(config, input_dim=emissions_dim, z_dim=2, x_dim=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if mps is available\n",
    "# device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')\n",
    "# print(device)\n",
    "# model = model.to(device)\n",
    "# spikes = spikes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (behavior_batch, spikes_batch) in enumerate(test_loader):\n",
    "            y_recon, (mu, A), (z, x), behavior_batch_pred = model(spikes_batch)\n",
    "            _, loss_l = model.loss(spikes_batch, y_recon, mu, A, z, x, behavior_batch_pred, behavior_batch)\n",
    "            test_loss += np.array(loss_l)\n",
    "    # divide loss by total number of samples in dataloader    \n",
    "    return test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, val_loader):\n",
    "    train_losses, test_losses = [], []\n",
    "    test_every = config['test_every']\n",
    "    early_stop = EarlyStopping(patience=config['early_stop']['patience'], delta=config['early_stop']['delta'],\n",
    "                            trace_func=print)\n",
    "    save_model = True\n",
    "    for epoch in range(num_epochs):\n",
    "        # forward pass\n",
    "        epoch_loss = 0\n",
    "        for i, (behavior_batch, spikes_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            y_recon, (mu, A), (z, x), behavior_pred = model(spikes_batch)\n",
    "            loss, loss_l = model.loss(spikes_batch, y_recon, mu, A, z, x, behavior_pred, behavior_batch)        \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            epoch_loss += np.array(loss_l)\n",
    "        train_losses.append(epoch_loss/len(train_loader))\n",
    "        # test loss\n",
    "        if (epoch+1) % test_every == 0:\n",
    "            test_loss = test(model, val_loader)\n",
    "            test_losses.append(test_loss)\n",
    "            early_stop(np.sum(test_loss), model, save_model=save_model, save_prefix='best')\n",
    "            print('Epoch [{}/{}], Train Loss: {}, Test Loss: {}'.format(epoch+1, num_epochs, train_losses[-1], test_losses[-1]))            \n",
    "            if early_stop.slow_down:\n",
    "                test_every = config['early_stop']['test_every_new']\n",
    "            else:\n",
    "                test_every = config['test_every']\n",
    "            if early_stop.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    # compute min test loss and return it    \n",
    "    return np.min([np.sum(x) for x in test_losses])\n",
    "\n",
    "\n",
    "# train model\n",
    "min_test_loss = train(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = model.vae.c1.weight.detach().numpy(), model.vae.c2.weight.detach().numpy()\n",
    "print(c1.T.dot(c2)/(np.linalg.norm(c1)*np.linalg.norm(c2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_recon, (mu, A), _, _ = model.forward(spikes)    \n",
    "    # run on only test\n",
    "    y_recon_test, (mu_test, A_test), _, _ = model.forward(spikes_test)\n",
    "    \n",
    "# convert to numpy\n",
    "y_recon_np = y_recon.detach().numpy()\n",
    "spikes_np = spikes.detach().numpy()\n",
    "y_recon_test_np = y_recon_test.detach().numpy()\n",
    "spikes_test_np = spikes_test.detach().numpy()\n",
    "# compute bits/spike\n",
    "bits_per_spike_all = utils.bits_per_spike(y_recon_np, spikes_np)\n",
    "bits_per_spike_test = utils.bits_per_spike(y_recon_test_np, spikes_test_np)\n",
    "# show distribution of bits per spike\n",
    "plt.hist(bits_per_spike_all, bins=50)\n",
    "plt.ylabel('Bits/spike')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()\n",
    "# print('Bits per spike: {}'.format(bits_per_spike))\n",
    "print(\"Bits per spike all: {}, test: {}\".format(np.sum(bits_per_spike_all), np.sum(bits_per_spike_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = np.mean(A.numpy()[:, 10, :, :], axis=0)\n",
    "cov = a_t * a_t.T\n",
    "# print(cov.shape, spikes_np.shape)\n",
    "plt.imshow(cov)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PSTH of reconstructed and original data\n",
    "averaged_recon, averaged_original = y_recon.mean(axis=0), spikes_np.mean(axis=0)\n",
    "# stimulus and choice important\n",
    "common = [12, 14, 4, 31]\n",
    "stim_neurons = [15, 11, 33, 30]\n",
    "choice_neurons = [16, 2, 6, 8]\n",
    "# plot each in a 5x7 grid\n",
    "fig, axs = plt.subplots(5, 7, figsize=(12, 9))\n",
    "# set title of figure\n",
    "fig.suptitle('yellow: choice, green: stimulus, pink: common')\n",
    "for i in range(5):\n",
    "    for j in range(7):\n",
    "        neuron_idx = i*7+j        \n",
    "        axs[i, j].plot(averaged_recon[:, neuron_idx], label='recon', color='red')\n",
    "        axs[i, j].plot(averaged_original[:, neuron_idx], label='original', color='blue')\n",
    "        # no ticks\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "        # set title of plot to neuron index\n",
    "        # print only 2 decimal places        \n",
    "        axs[i, j].set_title('{}: {:.4f}'.format(neuron_idx, bits_per_spike_all[neuron_idx]))\n",
    "        # set background color of plot to green if neuron in choice\n",
    "        if neuron_idx in choice_neurons:\n",
    "            axs[i, j].set_facecolor('yellow')\n",
    "        # set background color of plot to red if neuron in stimulus\n",
    "        if neuron_idx in stim_neurons:\n",
    "            axs[i, j].set_facecolor('green')\n",
    "        # set background color of plot to blue if neuron in common\n",
    "        if neuron_idx in common:\n",
    "            axs[i, j].set_facecolor('pink')\n",
    "axs[0, 0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trial averaged latent space\n",
    "z, x = torch.sigmoid(mu[:, :, :model.vae.z_dim]).numpy(), mu[:, :, model.vae.z_dim:].numpy()\n",
    "# z_std, x_std = np.std(z, axis=0), np.std(x, axis=0)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "z_avg, x_avg = np.mean(z, axis=0), np.mean(x, axis=0)\n",
    "# make x ticks of range 0.1 from -2 to 0.5\n",
    "t = np.arange(-1, 0.5, bin_len)\n",
    "axs[0].plot(t, z_avg[:, 0], label='z0')\n",
    "axs[0].plot(t, z_avg[:, 1], label='z1')\n",
    "axs[1].plot(t, x_avg[:, 0], label='x0')\n",
    "axs[1].plot(t, x_avg[:, 1], label='x1')\n",
    "axs[0].set_title('z')\n",
    "axs[1].set_title('x')\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group x for stimulus and choice\n",
    "stim, choice = behaviour_data[:, 0].numpy(), behaviour_data[:, 1].numpy()\n",
    "# group x for stimulus\n",
    "x_stim_left, x_stim_right = x[stim == 1].mean(axis=0), x[stim == 0].mean(axis=0)\n",
    "x_choice_left, x_choice_right = x[choice == 1].mean(axis=0), x[choice == 0].mean(axis=0)\n",
    "# plot x for stimulus and choice\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].plot(t, x_stim_left[:, 0], label='stim left (x0)', color='red', linestyle='--')\n",
    "axs[0].plot(t, x_stim_left[:, 1], label='stim left (x1)', color='red')\n",
    "axs[0].plot(t, x_stim_right[:, 0], label='stim right (x0)', color='blue', linestyle='--')\n",
    "axs[0].plot(t, x_stim_right[:, 1], label='stim right (x1)', color='blue')\n",
    "axs[0].set_title('x grouped by stimulus')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(t, x_choice_left[:, 0], label='choice left (x0)', color='red', linestyle='--')\n",
    "axs[1].plot(t, x_choice_left[:, 1], label='choice left (x1)', color='red')\n",
    "axs[1].plot(t, x_choice_right[:, 0], label='choice right (x0)', color='blue', linestyle='--')\n",
    "axs[1].plot(t, x_choice_right[:, 1], label='choice right (x1)', color='blue')\n",
    "axs[1].set_title('x grouped by choice')\n",
    "axs[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()    \n",
    "    _, (mu_train, A_train), (z_train, x_train), behavior_pred_train = model.forward(spikes_train)\n",
    "    _, (mu_test, A_test), (z_test, x_test), behavior_pred_test = model.forward(spikes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if behavior_pred_train is None:\n",
    "# train the linear decoder for behavior\n",
    "# create linear decoder\n",
    "linear_decoder = LinearAccDecoder(input_dim=2)\n",
    "optimizer = torch.optim.Adam(linear_decoder.parameters(), lr=0.01)\n",
    "decoder_train_l, decoder_test_l = [], []\n",
    "for epoch in range(5000):\n",
    "    # forward pass        \n",
    "    linear_decoder.train()\n",
    "    behavior_pred = linear_decoder(x_train, z_train)\n",
    "    # behavior_pred = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    loss = linear_decoder.loss(behavior_pred, behaviour_data_train)\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    epoch_loss = loss.item()    \n",
    "    decoder_train_l.append(epoch_loss/len(train_loader))\n",
    "    # test loss\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        test_loss = test(model, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, num_epochs, decoder_train_l[-1], test_losses[-1]))            \n",
    "    # if epoch % 10 == 0:\n",
    "    #     torch.save(model.state_dict(), os.path.join(base_path, 'vae_model_{}.pt'.format(epoch)))\n",
    "    #     print('Model saved at epoch {}'.format(epoch))\n",
    "\n",
    "with torch.no_grad():\n",
    "    behavior_pred_train = linear_decoder(x_train, z_train).detach()\n",
    "    behavior_pred_test = linear_decoder(x_test, z_test).detach()\n",
    "    # behavior_pred_train = linear_decoder(mu_train[:, :, :2], mu_train[:, :, 2:])\n",
    "    # behavior_pred_test = linear_decoder(mu_test[:, :, :2], mu_test[:, :, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted behaviour\n",
    "# convert to numpy\n",
    "pred_train = behavior_pred_train.numpy() > 0\n",
    "pred_test = behavior_pred_test.numpy() > 0\n",
    "# compute accuracy\n",
    "accuracy_train_stim = accuracy_score(behaviour_data_train.numpy()[:, 0], pred_train[:, 0])\n",
    "accuracy_test_stim = accuracy_score(behaviour_data_test.numpy()[:, 0], pred_test[:, 0])\n",
    "print('Stimulus Accuracy - train: {:.4f}, test: {:.4f}'.format(accuracy_train_stim, accuracy_test_stim))\n",
    "# do the same for choice\n",
    "accuracy_train_choice = accuracy_score(behaviour_data_train.numpy()[:, 1], pred_train[:, 1])\n",
    "accuracy_test_choice = accuracy_score(behaviour_data_test.numpy()[:, 1], pred_test[:, 1])\n",
    "print('Choice Accuracy - train: {:.4f}, test: {:.4f}'.format(accuracy_train_choice, accuracy_test_choice))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine a random trial\n",
    "trial_idx = np.random.randint(num_trials)\n",
    "# plot z and x\n",
    "fig, axs = plt.subplots(3, 1, figsize=(5, 8))\n",
    "# plot z\n",
    "axs[0].plot(t, z[trial_idx, :, 0], label='z0')\n",
    "axs[0].plot(t, z[trial_idx, :, 1], label='z1')\n",
    "axs[0].set_title('z')\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend()\n",
    "axs[0].set_xticks([])\n",
    "# plot num contacts\n",
    "axs[1].plot(t, num_contacts[trial_idx])\n",
    "axs[1].set_title('num contacts')\n",
    "axs[1].set_xticks([])\n",
    "# plot x\n",
    "axs[2].plot(t, x[trial_idx, :, 0], label='x0')\n",
    "axs[2].plot(t, x[trial_idx, :, 1], label='x1')\n",
    "axs[2].set_title('x, stimulus: {}, choice: {}'.format(stim[trial_idx].astype(int), choice[trial_idx].astype(int)))\n",
    "axs[2].set_ylim(-2, 2)\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
