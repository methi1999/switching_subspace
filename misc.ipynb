{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 100\n",
    "d = 5\n",
    "mu1 = torch.zeros(l, d)\n",
    "sigma1 = torch.eye(d, d).repeat(l, 1, 1)\n",
    "mu = torch.randn(l, d)\n",
    "A = torch.tril(torch.randn(l, d, d))\n",
    "# make diagonal positive\n",
    "diag = torch.diagonal(A, dim1=-2, dim2=-1)        \n",
    "diag = nn.Softplus()(diag)\n",
    "# set diag of A to diag\n",
    "A = A - torch.diag_embed(torch.diagonal(A, dim1=-2, dim2=-1)) + torch.diag_embed(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.distributions.MultivariateNormal(mu1, scale_tril=sigma1)\n",
    "q = torch.distributions.MultivariateNormal(mu, scale_tril=A)\n",
    "# compute the kl divergence\n",
    "kl_loss = torch.distributions.kl_divergence(q, p).sum()\n",
    "print(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = torch.bmm(A, torch.transpose(A, 1, 2))\n",
    "det = torch.det(cov)\n",
    "kl_loss = 0.5 * torch.sum(torch.sum(mu.pow(2), dim=1) + torch.einsum(\"...ii\", cov) - mu.shape[1] - torch.log(det))\n",
    "print(kl_loss, 'original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, dim, time = 10, 5, 100\n",
    "bd = torch.randn(batch, time, 2*dim)\n",
    "prec = torch.zeros(batch, dim, time, time)\n",
    "for i in range(dim):\n",
    "    diag_elems = bd[:, :, i]\n",
    "    off_diag_elems = bd[:, :-1, i+dim]\n",
    "    # fill elements\n",
    "    prec[:, i, :, :] = torch.diag_embed(diag_elems) + torch.diag_embed(off_diag_elems, offset=1, dim1=-2, dim2=-1)\n",
    "    prec[:, i, :, :] = torch.bmm(prec[:, i, :, :].transpose(1, 2), prec[:, i, :, :])\n",
    "    print(prec[0, i, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae_unimodal import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TimeSeries(10, 8, 2, 25, False, 1, False, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(5, 25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mithileshvaidya/miniforge3/lib/python3.10/site-packages/torch/distributions/distribution.py:167: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 25])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a.forward(y)\n",
    "out[0].sample_n(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
